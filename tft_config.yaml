# Temporal Fusion Transformer 配置文件示例
# 
# 使用方法:
# 1. 根据你的需求修改参数
# 2. 在训练脚本中加载此配置
#
# 示例代码:
# import yaml
# with open('tft_config.yaml', 'r') as f:
#     config = yaml.safe_load(f)

# ==================== 数据配置 ====================
data:
  # 数据文件路径（支持 .csv, .csv.gz）
  data_path: './gp_models/mom_ETHUSDT_15m_1_2025-01-01_2025-03-01_2025-03-01_2025-04-01.csv.gz'
  
  # 目标变量列名
  target_column: 'label'
  
  # GP因子列名前缀（如果你的因子列有统一前缀）
  gp_factor_prefix: 'gp_'
  
  # 训练/验证集分割比例
  val_ratio: 0.2
  
  # 滑动窗口步长
  stride_train: 1      # 训练集步长（小步长=更多样本，但训练慢）
  stride_val: 5        # 验证集步长（大步长=更快验证）
  
  # 数据缩放方法: 'standard', 'robust', 'minmax', 'none'
  scaler_method: 'robust'

# ==================== 模型架构配置 ====================
model:
  # 时间窗口配置
  encoder_length: 60    # 历史窗口长度（观测多少个时间步）
  decoder_length: 10    # 预测窗口长度（预测多少个时间步）
  
  # 模型大小配置
  hidden_size: 128      # 隐藏层维度（越大模型越强大，但训练越慢）
  lstm_layers: 2        # LSTM层数（1-3层通常足够）
  num_attention_heads: 4  # 注意力头数（必须能整除hidden_size）
  dropout: 0.2          # Dropout率（防止过拟合，0.1-0.3合适）
  
  # 输入特征配置
  # 注意：这些会在运行时自动从数据推断
  static_variables: 0        # 静态变量数量（不随时间变化的特征）
  known_regular_inputs: 4    # 已知输入数量（如时间特征：hour, day, etc.）
  observed_inputs: auto      # 观测输入数量（GP因子数量，自动推断）
  output_size: 1            # 输出维度（单变量预测=1）

# ==================== 训练配置 ====================
training:
  # 基础训练参数
  batch_size: 64          # 批大小（根据显存调整：64, 128, 256）
  learning_rate: 0.001    # 初始学习率（1e-3 或 1e-4）
  max_epochs: 100         # 最大训练轮数
  patience: 15            # 早停耐心值（多少轮无改进则停止）
  
  # 优化器配置
  optimizer: 'adam'       # 优化器类型：'adam', 'adamw', 'sgd'
  weight_decay: 1e-5      # L2正则化系数
  
  # 学习率调度器
  scheduler: 'reduce_on_plateau'  # 'reduce_on_plateau', 'cosine', 'step'
  scheduler_factor: 0.5           # 学习率衰减因子
  scheduler_patience: 5           # 学习率调度耐心值
  
  # 梯度裁剪
  grad_clip_norm: 1.0     # 梯度裁剪最大范数（防止梯度爆炸）
  
  # 数据加载
  num_workers: 0          # DataLoader工作进程数（Windows设为0，Linux/Mac可设为4-8）
  pin_memory: true        # 是否固定内存（GPU训练时建议True）

# ==================== 设备配置 ====================
device:
  # 设备类型：'cuda', 'cpu', 'mps'(Mac M1/M2), 'auto'(自动检测)
  type: 'auto'
  
  # GPU设备ID（如果有多个GPU）
  gpu_id: 0

# ==================== 输出配置 ====================
output:
  # 保存目录
  save_dir: './tft_results'
  
  # 是否自动添加时间戳到保存目录
  add_timestamp: true
  
  # 保存的内容
  save_model: true        # 保存模型权重
  save_config: true       # 保存配置文件
  save_scaler: true       # 保存数据缩放器
  save_plots: true        # 保存可视化图表
  
  # 检查点保存
  save_checkpoints: true  # 是否保存训练检查点
  checkpoint_frequency: 5 # 每多少轮保存一次检查点

# ==================== 可视化配置 ====================
visualization:
  # 训练历史可视化
  plot_training_history: true
  
  # 预测结果可视化
  plot_predictions: true
  num_prediction_samples: 500  # 绘制多少个预测样本
  
  # 注意力权重可视化
  plot_attention: true
  
  # 变量重要性可视化
  plot_variable_importance: true

# ==================== 高级配置 ====================
advanced:
  # 损失函数：'mse', 'mae', 'huber', 'quantile'
  loss_function: 'mse'
  
  # 分位数损失配置（仅当loss_function='quantile'时使用）
  quantiles: [0.1, 0.5, 0.9]
  
  # 混合精度训练（GPU加速，节省显存）
  mixed_precision: false
  
  # 梯度累积步数（显存不足时可使用）
  gradient_accumulation_steps: 1
  
  # 是否使用teacher forcing（训练时使用真实历史目标值）
  use_teacher_forcing: false
  
  # 随机种子（保证可重复性）
  random_seed: 42

# ==================== 特征工程配置 ====================
feature_engineering:
  # 是否自动生成时间特征
  auto_time_features: true
  
  # 时间特征列表
  time_features:
    - hour          # 小时 (0-23)
    - dayofweek     # 星期几 (0-6)
    - day           # 日期 (1-31)
    - month         # 月份 (1-12)
    # - quarter     # 季度 (1-4)
    # - year        # 年份
  
  # 是否对GP因子进行winsorization（去除极端值）
  winsorize_factors: true
  winsorize_limits: [0.01, 0.99]  # 去除1%和99%分位数外的极端值
  
  # 是否进行因子筛选（去除低相关性因子）
  factor_selection: false
  factor_selection_method: 'correlation'  # 'correlation', 'mutual_info', 'lasso'
  factor_selection_threshold: 0.05        # 相关性阈值

# ==================== 评估指标配置 ====================
evaluation:
  # 计算的指标
  metrics:
    - 'mse'         # 均方误差
    - 'mae'         # 平均绝对误差
    - 'rmse'        # 均方根误差
    - 'mape'        # 平均绝对百分比误差
    - 'r2'          # R平方
  
  # 是否计算方向准确率（预测涨跌方向的准确率）
  direction_accuracy: true
  
  # 是否计算Sharpe比率（用于交易策略评估）
  calculate_sharpe: true

# ==================== 实验追踪配置 ====================
experiment_tracking:
  # 是否启用实验追踪（需要安装 tensorboard 或 wandb）
  enabled: false
  
  # 追踪工具：'tensorboard', 'wandb', 'mlflow'
  tool: 'tensorboard'
  
  # 项目名称
  project_name: 'crypto_tft'
  
  # 实验名称（留空则自动生成）
  experiment_name: null

# ==================== 示例配置 ====================
# 
# 快速原型配置（快速测试，精度较低）:
# model.hidden_size: 64
# model.lstm_layers: 1
# training.batch_size: 128
# training.max_epochs: 20
#
# 高性能配置（追求最佳精度）:
# model.hidden_size: 256
# model.lstm_layers: 3
# model.num_attention_heads: 8
# training.batch_size: 32
# training.max_epochs: 200
#
# 内存受限配置（显存/内存不足）:
# model.hidden_size: 64
# training.batch_size: 16
# training.gradient_accumulation_steps: 4
# data.stride_train: 2

