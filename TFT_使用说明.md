# Temporal Fusion Transformer (TFT) ä½¿ç”¨è¯´æ˜Ž

æœ¬é¡¹ç›®å®žçŽ°äº†å®Œæ•´çš„ Temporal Fusion Transformer æ¨¡åž‹ï¼Œç”¨äºŽåŠ å¯†è´§å¸æ—¶é—´åºåˆ—é¢„æµ‹ã€‚

## ðŸ“‹ ç›®å½•

- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [å®‰è£…ä¾èµ–](#å®‰è£…ä¾èµ–)
- [æ–‡ä»¶è¯´æ˜Ž](#æ–‡ä»¶è¯´æ˜Ž)
- [ä½¿ç”¨æ–¹æ³•](#ä½¿ç”¨æ–¹æ³•)
- [é…ç½®è¯´æ˜Ž](#é…ç½®è¯´æ˜Ž)
- [æ¨¡åž‹æž¶æž„](#æ¨¡åž‹æž¶æž„)
- [æœ€ä½³å®žè·µ](#æœ€ä½³å®žè·µ)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

## ðŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
# å®‰è£… PyTorch (æ ¹æ®ä½ çš„ç³»ç»Ÿé€‰æ‹©)
# CUDA ç‰ˆæœ¬ (NVIDIA GPU)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# CPU ç‰ˆæœ¬
pip install torch torchvision torchaudio

# Mac M1/M2
pip install torch torchvision torchaudio

# å®‰è£…å…¶ä»–ä¾èµ–
pip install -r requirements.txt
```

### 2. å‡†å¤‡æ•°æ®

ç¡®ä¿ä½ çš„æ•°æ®åŒ…å«ï¼š
- GPç”Ÿæˆçš„å› å­åˆ—ï¼ˆå¦‚ `gp_0`, `gp_1`, ...ï¼‰
- ç›®æ ‡å˜é‡åˆ—ï¼ˆå¦‚ `label`ï¼‰
- æ—¶é—´ç´¢å¼•

ç¤ºä¾‹æ•°æ®æ ¼å¼ï¼š
```
timestamp,gp_0,gp_1,gp_2,...,label
2025-01-01 00:00:00,0.5,-0.3,1.2,...,0.002
2025-01-01 00:15:00,0.6,-0.2,1.1,...,0.003
...
```

### 3. è¿è¡Œè®­ç»ƒ

```bash
python tft_main.py
```

å°±è¿™ä¹ˆç®€å•ï¼æ¨¡åž‹ä¼šè‡ªåŠ¨ï¼š
- åŠ è½½æ•°æ®
- é¢„å¤„ç†ç‰¹å¾
- è®­ç»ƒæ¨¡åž‹
- ä¿å­˜ç»“æžœå’Œå¯è§†åŒ–

## ðŸ“¦ æ–‡ä»¶è¯´æ˜Ž

```
crypto-workstation/
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ temporal_fusion_transformer.py  # TFTæ¨¡åž‹æž¶æž„
â”‚   â””â”€â”€ tft_data_processor.py          # æ•°æ®é¢„å¤„ç†
â”œâ”€â”€ tft_main.py                         # è®­ç»ƒä¸»ç¨‹åº
â”œâ”€â”€ tft_config.yaml                     # é…ç½®æ–‡ä»¶ç¤ºä¾‹
â”œâ”€â”€ TFT_ä½¿ç”¨è¯´æ˜Ž.md                     # æœ¬æ–‡æ¡£
â””â”€â”€ requirements.txt                    # ä¾èµ–åŒ…ï¼ˆå·²æ›´æ–°ï¼‰
```

## ðŸ“– ä½¿ç”¨æ–¹æ³•

### æ–¹æ³•ä¸€ï¼šä½¿ç”¨é»˜è®¤é…ç½®ï¼ˆæŽ¨èæ–°æ‰‹ï¼‰

```python
python tft_main.py
```

### æ–¹æ³•äºŒï¼šä¿®æ”¹é…ç½®æ–‡ä»¶

1. ç¼–è¾‘ `tft_config.yaml`
2. ä¿®æ”¹å‚æ•°ï¼ˆå¦‚batch_size, hidden_sizeç­‰ï¼‰
3. åœ¨ä»£ç ä¸­åŠ è½½é…ç½®ï¼š

```python
import yaml

with open('tft_config.yaml', 'r') as f:
    config = yaml.safe_load(f)

# ä½¿ç”¨é…ç½®
BATCH_SIZE = config['training']['batch_size']
HIDDEN_SIZE = config['model']['hidden_size']
```

### æ–¹æ³•ä¸‰ï¼šè‡ªå®šä¹‰ä»£ç 

```python
from model.temporal_fusion_transformer import TemporalFusionTransformer
from model.tft_data_processor import TFTDataProcessor
import pandas as pd

# 1. åŠ è½½æ•°æ®
df = pd.read_csv('your_data.csv')

# 2. æ•°æ®é¢„å¤„ç†
processor = TFTDataProcessor(
    target_column='label',
    encoder_length=60,
    decoder_length=10,
    batch_size=64
)

# 3. å‡†å¤‡ç‰¹å¾
processed_df, feature_config = processor.prepare_data_from_gp_factors(
    df,
    factor_columns=['gp_0', 'gp_1', 'gp_2'],  # ä½ çš„GPå› å­
)

# 4. åˆ›å»ºæ•°æ®é›†
train_dataset, val_dataset = processor.create_datasets(
    processed_df,
    feature_config
)

train_loader, val_loader = processor.create_dataloaders(
    train_dataset,
    val_dataset
)

# 5. åˆ›å»ºæ¨¡åž‹
model = TemporalFusionTransformer(
    observed_inputs=len(feature_config['observed']),
    known_regular_inputs=len(feature_config['known']),
    hidden_size=128,
    lstm_layers=2,
    num_attention_heads=4,
    encoder_length=60,
    decoder_length=10,
)

# 6. è®­ç»ƒ
from model.temporal_fusion_transformer import TFTTrainer

trainer = TFTTrainer(
    model=model,
    train_loader=train_loader,
    val_loader=val_loader,
    device='cuda',
)

history = trainer.train()
```

## âš™ï¸ é…ç½®è¯´æ˜Ž

### å…³é”®å‚æ•°

| å‚æ•° | è¯´æ˜Ž | æŽ¨èå€¼ |
|------|------|--------|
| `encoder_length` | åŽ†å²çª—å£é•¿åº¦ | 30-120 (15åˆ†é’Ÿæ•°æ®ï¼š30=7.5å°æ—¶) |
| `decoder_length` | é¢„æµ‹çª—å£é•¿åº¦ | 5-20 (15åˆ†é’Ÿæ•°æ®ï¼š10=2.5å°æ—¶) |
| `hidden_size` | éšè—å±‚å¤§å° | 64-256 (è¶Šå¤§è¶Šå¼ºå¤§ä½†è¶Šæ…¢) |
| `lstm_layers` | LSTMå±‚æ•° | 1-3 |
| `num_attention_heads` | æ³¨æ„åŠ›å¤´æ•° | 4-8 (å¿…é¡»èƒ½æ•´é™¤hidden_size) |
| `dropout` | DropoutçŽ‡ | 0.1-0.3 |
| `batch_size` | æ‰¹å¤§å° | 32-128 |
| `learning_rate` | å­¦ä¹ çŽ‡ | 1e-4 ~ 1e-3 |

### æ•°æ®å‚æ•°

```yaml
data:
  encoder_length: 60      # ä½¿ç”¨60ä¸ªæ—¶é—´æ­¥çš„åŽ†å²æ•°æ®
  decoder_length: 10      # é¢„æµ‹æœªæ¥10ä¸ªæ—¶é—´æ­¥
  stride_train: 1         # è®­ç»ƒæ—¶æ¯æ¬¡æ»‘åŠ¨1æ­¥ï¼ˆæ›´å¤šæ ·æœ¬ï¼‰
  stride_val: 5           # éªŒè¯æ—¶æ¯æ¬¡æ»‘åŠ¨5æ­¥ï¼ˆæ›´å¿«ï¼‰
```

### æ¨¡åž‹å‚æ•°

```yaml
model:
  hidden_size: 128        # éšè—å±‚ç»´åº¦
  lstm_layers: 2          # LSTMå±‚æ•°
  num_attention_heads: 4  # æ³¨æ„åŠ›å¤´æ•°
  dropout: 0.2            # DropoutçŽ‡
```

## ðŸ—ï¸ æ¨¡åž‹æž¶æž„

TFT ç”±ä»¥ä¸‹ç»„ä»¶æž„æˆï¼š

### 1. å˜é‡é€‰æ‹©ç½‘ç»œ (Variable Selection Network)
- è‡ªåŠ¨é€‰æ‹©æœ€é‡è¦çš„è¾“å…¥ç‰¹å¾
- æä¾›ç‰¹å¾é‡è¦æ€§è§£é‡Š

### 2. LSTM ç¼–ç å™¨-è§£ç å™¨
- **ç¼–ç å™¨**: å¤„ç†åŽ†å²è§‚æµ‹æ•°æ®
- **è§£ç å™¨**: ç”Ÿæˆæœªæ¥é¢„æµ‹

### 3. å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶
- æ•æ‰ä¸åŒæ—¶é—´æ­¥ä¹‹é—´çš„ä¾èµ–å…³ç³»
- æä¾›æ—¶é—´æ³¨æ„åŠ›å¯è§†åŒ–

### 4. é—¨æŽ§æ®‹å·®ç½‘ç»œ (GRN)
- éžçº¿æ€§ç‰¹å¾å˜æ¢
- é—¨æŽ§æœºåˆ¶æŽ§åˆ¶ä¿¡æ¯æµ

### 5. é™æ€åå˜é‡å¤„ç†
- å¤„ç†ä¸éšæ—¶é—´å˜åŒ–çš„ç‰¹å¾
- ä¸Šä¸‹æ–‡å‘é‡å¢žå¼º

## ðŸ’¡ æœ€ä½³å®žè·µ

### 1. æ•°æ®é¢„å¤„ç†

```python
# âœ… æŽ¨èï¼šä½¿ç”¨ Robust Scalerï¼ˆå¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿï¼‰
processor = TFTDataProcessor(scaler_method='robust')

# âŒ é¿å…ï¼šç›´æŽ¥ä½¿ç”¨åŽŸå§‹æ•°æ®
```

### 2. çª—å£é•¿åº¦é€‰æ‹©

```python
# 15åˆ†é’Ÿæ•°æ®å»ºè®®é…ç½®
encoder_length = 60   # 15å°æ—¶åŽ†å²
decoder_length = 10   # 2.5å°æ—¶é¢„æµ‹

# 1å°æ—¶æ•°æ®å»ºè®®é…ç½®
encoder_length = 24   # 1å¤©åŽ†å²
decoder_length = 6    # 6å°æ—¶é¢„æµ‹
```

### 3. ç‰¹å¾é€‰æ‹©

```python
# ä½¿ç”¨é«˜è´¨é‡çš„GPå› å­
# âœ… æŽ¨èï¼šä½¿ç”¨GPç­›é€‰åŽçš„å› å­ï¼ˆIC > 0.05ï¼‰
gp_factors = [col for col in df.columns if col.startswith('gp_') and ic[col] > 0.05]

# âŒ é¿å…ï¼šä½¿ç”¨æ‰€æœ‰åŽŸå§‹ç‰¹å¾ï¼ˆå¯èƒ½åŒ…å«å™ªå£°ï¼‰
```

### 4. è¶…å‚æ•°è°ƒä¼˜é¡ºåº

1. **å…ˆè°ƒå¤§æ¡†æž¶**: `encoder_length`, `decoder_length`
2. **å†è°ƒæ¨¡åž‹å®¹é‡**: `hidden_size`, `lstm_layers`
3. **æœ€åŽè°ƒè®­ç»ƒå‚æ•°**: `learning_rate`, `batch_size`, `dropout`

### 5. è®­ç»ƒæŠ€å·§

```python
# ä½¿ç”¨æ¢¯åº¦è£å‰ªé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

# ä½¿ç”¨å­¦ä¹ çŽ‡è°ƒåº¦å™¨
scheduler = ReduceLROnPlateau(optimizer, patience=5, factor=0.5)

# ä½¿ç”¨æ—©åœé˜²æ­¢è¿‡æ‹Ÿåˆ
if val_loss > best_val_loss:
    epochs_without_improvement += 1
    if epochs_without_improvement >= patience:
        break
```

## ðŸŽ¯ è¯„ä¼°æŒ‡æ ‡

æ¨¡åž‹ä¼šè‡ªåŠ¨è®¡ç®—ä»¥ä¸‹æŒ‡æ ‡ï¼š

| æŒ‡æ ‡ | è¯´æ˜Ž | è¶Šå°è¶Šå¥½/è¶Šå¤§è¶Šå¥½ |
|------|------|-------------------|
| MSE | å‡æ–¹è¯¯å·® | â†“ è¶Šå°è¶Šå¥½ |
| MAE | å¹³å‡ç»å¯¹è¯¯å·® | â†“ è¶Šå°è¶Šå¥½ |
| RMSE | å‡æ–¹æ ¹è¯¯å·® | â†“ è¶Šå°è¶Šå¥½ |
| MAPE | å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·® | â†“ è¶Šå°è¶Šå¥½ |
| RÂ² | å†³å®šç³»æ•° | â†‘ è¶Šå¤§è¶Šå¥½ |

### å¦‚ä½•åˆ¤æ–­æ¨¡åž‹å¥½åï¼Ÿ

```python
# å¥½çš„æ¨¡åž‹
RÂ² > 0.3         # è§£é‡Šäº†30%ä»¥ä¸Šçš„æ–¹å·®
MAPE < 5%        # å¹³å‡è¯¯å·®å°äºŽ5%
val_loss < train_loss * 1.2  # éªŒè¯æŸå¤±ä¸è¶…è¿‡è®­ç»ƒæŸå¤±çš„20%

# éœ€è¦æ”¹è¿›
RÂ² < 0.1         # é¢„æµ‹èƒ½åŠ›è¾ƒå¼±
MAPE > 10%       # è¯¯å·®è¾ƒå¤§
val_loss > train_loss * 2    # ä¸¥é‡è¿‡æ‹Ÿåˆ
```

## ðŸ“Š å¯è§†åŒ–è¾“å‡º

è®­ç»ƒå®ŒæˆåŽä¼šç”Ÿæˆï¼š

### 1. è®­ç»ƒåŽ†å²å›¾ (`training_history.png`)
- è®­ç»ƒ/éªŒè¯æŸå¤±æ›²çº¿
- å­¦ä¹ çŽ‡å˜åŒ–æ›²çº¿

### 2. é¢„æµ‹ç»“æžœå›¾ (`predictions.png`)
- æ—¶é—´åºåˆ—å¯¹æ¯”å›¾ï¼ˆçœŸå®žå€¼ vs é¢„æµ‹å€¼ï¼‰
- æ•£ç‚¹å›¾ï¼ˆé¢„æµ‹ç²¾åº¦å¯è§†åŒ–ï¼‰

### 3. æ³¨æ„åŠ›æƒé‡å›¾
- å±•ç¤ºæ¨¡åž‹å…³æ³¨çš„æ—¶é—´æ­¥
- å¸®åŠ©ç†è§£æ¨¡åž‹å†³ç­–

## â“ å¸¸è§é—®é¢˜

### Q1: CUDA out of memory (æ˜¾å­˜ä¸è¶³)

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# æ–¹æ³•1: å‡å°batch_size
batch_size = 32  # æˆ– 16

# æ–¹æ³•2: å‡å°hidden_size
hidden_size = 64

# æ–¹æ³•3: ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
gradient_accumulation_steps = 4
```

### Q2: è®­ç»ƒå¤ªæ…¢

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# æ–¹æ³•1: å¢žå¤§stride_train
stride_train = 2  # æˆ– 5

# æ–¹æ³•2: å‡å°‘num_workers
num_workers = 0

# æ–¹æ³•3: ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
from torch.cuda.amp import autocast, GradScaler
```

### Q3: è¿‡æ‹Ÿåˆï¼ˆéªŒè¯æŸå¤±è¿œå¤§äºŽè®­ç»ƒæŸå¤±ï¼‰

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# æ–¹æ³•1: å¢žå¤§dropout
dropout = 0.3  # æˆ– 0.4

# æ–¹æ³•2: ä½¿ç”¨æ›´å¤šæ•°æ®
# å¢žåŠ è®­ç»ƒæ ·æœ¬æ•°é‡

# æ–¹æ³•3: å‡å°æ¨¡åž‹å®¹é‡
hidden_size = 64
lstm_layers = 1

# æ–¹æ³•4: æ—©åœ
patience = 10
```

### Q4: é¢„æµ‹ç»“æžœä¸ä½³

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# 1. æ£€æŸ¥æ•°æ®è´¨é‡
df.isnull().sum()  # æ£€æŸ¥ç¼ºå¤±å€¼
df.describe()      # æ£€æŸ¥åˆ†å¸ƒ

# 2. æ£€æŸ¥ç‰¹å¾ç›¸å…³æ€§
correlation = df[gp_factors].corrwith(df['label'])
print(correlation.sort_values(ascending=False))

# 3. å¢žåŠ åŽ†å²çª—å£
encoder_length = 120  # å¢žåŠ åˆ°120

# 4. å°è¯•ä¸åŒçš„æŸå¤±å‡½æ•°
criterion = nn.L1Loss()  # MAEæŸå¤±
```

### Q5: å¦‚ä½•ç”¨äºŽå®žé™…äº¤æ˜“ï¼Ÿ

```python
# 1. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡åž‹
model.load_state_dict(torch.load('best_model.pth'))

# 2. å‡†å¤‡æœ€æ–°æ•°æ®
latest_data = get_latest_data()  # èŽ·å–æœ€æ–°60ä¸ªæ—¶é—´æ­¥

# 3. é¢„æµ‹
model.eval()
with torch.no_grad():
    prediction = model(latest_data)

# 4. ç”Ÿæˆäº¤æ˜“ä¿¡å·
if prediction > threshold:
    signal = 'BUY'
elif prediction < -threshold:
    signal = 'SELL'
else:
    signal = 'HOLD'
```

## ðŸ”§ é«˜çº§ç”¨æ³•

### 1. å¤šæ­¥é¢„æµ‹

```python
# TFTåŽŸç”Ÿæ”¯æŒå¤šæ­¥é¢„æµ‹
decoder_length = 20  # é¢„æµ‹æœªæ¥20æ­¥

# è¾“å‡ºå½¢çŠ¶: (batch, 20, 1)
predictions = model(historical_inputs, future_inputs)
```

### 2. æ¦‚çŽ‡é¢„æµ‹ï¼ˆåˆ†ä½æ•°å›žå½’ï¼‰

```python
from model.temporal_fusion_transformer import QuantileLoss

# ä½¿ç”¨åˆ†ä½æ•°æŸå¤±
criterion = QuantileLoss(quantiles=[0.1, 0.5, 0.9])

# è¾“å‡º: 10%, 50%, 90% åˆ†ä½æ•°é¢„æµ‹
# å¯ä»¥æž„å»ºé¢„æµ‹åŒºé—´
```

### 3. è¿ç§»å­¦ä¹ 

```python
# åœ¨æ–°å¸ç§ä¸Šå¾®è°ƒå·²è®­ç»ƒçš„æ¨¡åž‹
model.load_state_dict(torch.load('eth_model.pth'))

# å†»ç»“éƒ¨åˆ†å±‚
for param in model.lstm_encoder.parameters():
    param.requires_grad = False

# åªè®­ç»ƒæ³¨æ„åŠ›å’Œè¾“å‡ºå±‚
trainer = TFTTrainer(model, train_loader, val_loader)
trainer.train()
```

### 4. é›†æˆå¤šä¸ªæ¨¡åž‹

```python
models = [load_model(f'model_{i}.pth') for i in range(5)]

# å¹³å‡é¢„æµ‹
predictions = []
for model in models:
    pred = model(inputs)
    predictions.append(pred)

ensemble_pred = torch.mean(torch.stack(predictions), dim=0)
```

## ðŸ“š å‚è€ƒèµ„æ–™

- è®ºæ–‡: [Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting](https://arxiv.org/abs/1912.09363)
- PyTorchæ–‡æ¡£: https://pytorch.org/docs/stable/index.html
- æ—¶é—´åºåˆ—é¢„æµ‹: https://github.com/unit8co/darts

## ðŸ“ž æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·ï¼š
1. æŸ¥çœ‹æœ¬æ–‡æ¡£çš„"å¸¸è§é—®é¢˜"éƒ¨åˆ†
2. æ£€æŸ¥ `tft_config.yaml` é…ç½®æ˜¯å¦æ­£ç¡®
3. æŸ¥çœ‹è®­ç»ƒæ—¥å¿—å’Œé”™è¯¯ä¿¡æ¯

## ðŸŽ‰ å¼€å§‹ä½¿ç”¨å§ï¼

```bash
# ä¸€é”®å¯åŠ¨
python tft_main.py

# ç­‰å¾…è®­ç»ƒå®Œæˆï¼ŒæŸ¥çœ‹ç»“æžœï¼
```

ç¥ä½ è®­ç»ƒæ„‰å¿«ï¼ðŸš€

