"""
å¤šæ¨¡å‹é‡åŒ–äº¤æ˜“ç­–ç•¥ç±»
é‡æ„ç‰ˆæœ¬ - é¢å‘å¯¹è±¡è®¾è®¡

ä¸»è¦åŠŸèƒ½ï¼š
1. æŠ€æœ¯æŒ‡æ ‡å› å­ç”Ÿæˆ
2. å› å­ç­›é€‰å’Œé¢„å¤„ç†
3. å¤šæ¨¡å‹è®­ç»ƒï¼ˆOLS, Ridge, Lasso, XGBoost, LightGBMï¼‰
4. å›æµ‹å’Œé£é™©æŒ‡æ ‡è®¡ç®—
5. ç»“æœå¯è§†åŒ–
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib as mpl
import time
import math
import warnings
import os  # æ·»åŠ  os æ¨¡å—å¯¼å…¥
warnings.filterwarnings('ignore')

# è®¾ç½®matplotlibä¸­æ–‡å­—ä½“æ”¯æŒï¼ˆMacç³»ç»Ÿï¼‰
import platform

def setup_chinese_font_for_mac():
    """
    ä¸ºMacç³»ç»Ÿè®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
    """
    if platform.system() == 'Darwin':  # Macç³»ç»Ÿ
        # æ£€æŸ¥ç³»ç»Ÿå¯ç”¨å­—ä½“
        available_fonts = [f.name for f in mpl.font_manager.fontManager.ttflist]
        
        # Macç³»ç»Ÿå¸¸è§çš„ä¸­æ–‡å­—ä½“åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
        mac_chinese_fonts = [
            'PingFang SC',      # è‹¹æœé»˜è®¤ä¸­æ–‡å­—ä½“
            'Songti SC',        # å®‹ä½“
            'STSong',          # åæ–‡å®‹ä½“
            'Arial Unicode MS', # æ”¯æŒä¸­æ–‡çš„Arial
            'SimHei',          # é»‘ä½“
            'Hiragino Sans GB', # å†¬é’é»‘ä½“
            'STHeiti'          # åæ–‡é»‘ä½“
        ]
        
        # å¯»æ‰¾å¯ç”¨çš„ä¸­æ–‡å­—ä½“
        selected_font = None
        for font in mac_chinese_fonts:
            if font in available_fonts:
                selected_font = font
                break
        
        if selected_font:
            plt.rcParams['font.sans-serif'] = [selected_font] + plt.rcParams['font.sans-serif']
            plt.rcParams['axes.unicode_minus'] = False
            print(f"âœ… å·²è®¾ç½®ä¸­æ–‡å­—ä½“: {selected_font}")
            return True
        else:
            # å¦‚æœæ‰¾ä¸åˆ°ä¸­æ–‡å­—ä½“ï¼Œæä¾›è§£å†³æ–¹æ¡ˆ
            print("âš ï¸  æœªæ£€æµ‹åˆ°å¯ç”¨çš„ä¸­æ–‡å­—ä½“")
            print("ğŸ“ è§£å†³æ–¹æ¡ˆï¼š")
            print("1. ä½¿ç”¨Homebrewå®‰è£…ä¸­æ–‡å­—ä½“åŒ…ï¼š")
            print("   brew install --cask font-source-han-sans")
            print("   brew install --cask font-source-han-serif")
            print("2. æˆ–è€…æ‰‹åŠ¨ä¸‹è½½å®‰è£…æ€æºé»‘ä½“ï¼š")
            print("   https://github.com/adobe-fonts/source-han-sans")
            print("3. é‡å¯Pythonå†…æ ¸åé‡æ–°è¿è¡Œ")
            
            # è®¾ç½®åŸºæœ¬é…ç½®é¿å…è´Ÿå·æ˜¾ç¤ºé—®é¢˜
            plt.rcParams['axes.unicode_minus'] = False
            return False
    return True

# è°ƒç”¨å­—ä½“è®¾ç½®å‡½æ•°
setup_chinese_font_for_mac()

if platform.system() == 'Darwin':  # Macç³»ç»Ÿ
    # å°è¯•è®¾ç½®å¸¸è§çš„Macä¸­æ–‡å­—ä½“
    try:
        plt.rcParams['font.sans-serif'] = ['PingFang SC', 'Arial Unicode MS', 'SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
    except:
        # å¦‚æœä¸Šè¿°å­—ä½“ä¸å¯ç”¨ï¼Œä½¿ç”¨ç³»ç»Ÿé»˜è®¤å­—ä½“
        plt.rcParams['font.family'] = 'DejaVu Sans'
        plt.rcParams['axes.unicode_minus'] = False
        print("è­¦å‘Šï¼šæœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œå›¾è¡¨ä¸­çš„ä¸­æ–‡å¯èƒ½æ˜¾ç¤ºå¼‚å¸¸")

import talib as ta
from sklearn.linear_model import LinearRegression, Ridge, Lasso, LassoCV
from xgboost import XGBRegressor
import xgboost as xgb
import lightgbm as lgb
import joblib
import pickle

class QuantTradingStrategy:
    """
    å¤šæ¨¡å‹é‡åŒ–äº¤æ˜“ç­–ç•¥ç±»
    """
    
    def __init__(self, data_path, config=None):
        """
        åˆå§‹åŒ–ç­–ç•¥
        
        Args:
            data_path (str): æ•°æ®æ–‡ä»¶è·¯å¾„
            config (dict): é…ç½®å‚æ•°
        """
        self.data_path = data_path
        self.config = config or self._get_default_config()
        
        # æ•°æ®ç›¸å…³
        self.raw_data = None
        self.factor_data = None
        self.feed_data = None
        
        # è®­ç»ƒæ•°æ®
        self.X_train = None
        self.y_train = None
        self.X_test = None
        self.y_test = None
        self.train_set_end_index = None
        
        # æ¨¡å‹
        self.models = {}
        self.predictions = {}
        
        # å›æµ‹ç»“æœ
        self.backtest_results = {}
        self.performance_metrics = None
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        self._setup_chinese_font()
        
        print(f"ç­–ç•¥åˆå§‹åŒ–å®Œæˆ")
        # print(f"XGBoostç‰ˆæœ¬: {xgb.__version__}")
        # print(f"LightGBMç‰ˆæœ¬: {lgb.__version__}")
    
    def _setup_chinese_font(self):
        """è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ"""
        # å­—ä½“è®¾ç½®å·²åœ¨æ–‡ä»¶å¼€å¤´å®Œæˆï¼Œè¿™é‡Œåªåšç®€å•æ£€æŸ¥
        if platform.system() == 'Darwin':
            current_font = plt.rcParams['font.sans-serif'][0] if plt.rcParams['font.sans-serif'] else 'default'
            print(f"å½“å‰ä½¿ç”¨å­—ä½“: {current_font}")
        pass
    
    def _get_default_config(self):
        """è·å–é»˜è®¤é…ç½®"""
        return {
            'return_period': 1,  # æ”¶ç›Šç‡è®¡ç®—å‘¨æœŸ
            'corr_threshold': 0.3,  # ç›¸å…³æ€§ç­›é€‰é˜ˆå€¼
            'sharpe_threshold': 0.2,  # å¤æ™®æ¯”ç‡ç­›é€‰é˜ˆå€¼
            'train_end_date': '2016-12-30',  # è®­ç»ƒé›†ç»“æŸæ—¥æœŸ
            'position_size': 1.0,  # ä»“ä½å¤§å°
            'clip_num': 2.0,  # ä»“ä½é™åˆ¶
            'fixed_return': 0.0,  # æ— é£é™©æ”¶ç›Šç‡
            'fees_rate': 0.004,  # æ‰‹ç»­è´¹ç‡
            'model_save_path': './'  # æ”¹ä¸ºå½“å‰ç›®å½•
        }
    
    def load_data(self):
        """åŠ è½½å’Œé¢„å¤„ç†åŸå§‹æ•°æ®"""
        print("æ­£åœ¨åŠ è½½æ•°æ®...")
        
        # è¯»å–æ•°æ®
        self.raw_data = pd.read_pickle(self.data_path).reset_index()
        self.raw_data['timestamp'] = pd.to_datetime(self.raw_data['timestamp'])
        self.raw_data = self.raw_data.sort_values(by='timestamp', ascending=True)
        self.raw_data = self.raw_data.set_index('timestamp')
        
        # è®¡ç®—æ”¶ç›Šç‡
        t = self.config['return_period']
        self.raw_data['return'] = (self.raw_data['close'].shift(-t) / self.raw_data['close'] - 1)
        self.raw_data = self.raw_data.replace([np.nan], 0.0)
        
        print(f"æ•°æ®åŠ è½½å®Œæˆï¼Œå…± {len(self.raw_data)} æ¡è®°å½•")
        return self
    
    def generate_factors(self):
        """ç”ŸæˆæŠ€æœ¯æŒ‡æ ‡å› å­"""
        print("æ­£åœ¨ç”ŸæˆæŠ€æœ¯æŒ‡æ ‡å› å­...")
        
        fct_value = pd.DataFrame()
        close = self.raw_data['close']
        high = self.raw_data['high']
        low = self.raw_data['low']
        volume = self.raw_data['volume']
        
        # 1. MAç±»æŒ‡æ ‡
        fct_value['ma5'] = ta.MA(close, timeperiod=5, matype=0)
        fct_value['ma10'] = ta.MA(close, timeperiod=10, matype=0)
        fct_value['ma20'] = ta.MA(close, timeperiod=20, matype=0)
        fct_value['ma5diff'] = fct_value['ma5'] / close - 1
        fct_value['ma10diff'] = fct_value['ma10'] / close - 1
        fct_value['ma20diff'] = fct_value['ma20'] / close - 1
        
        # 2. å¸ƒæ—å¸¦æŒ‡æ ‡
        fct_value['h_line'], fct_value['m_line'], fct_value['l_line'] = ta.BBANDS(
            close, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)
        fct_value['stdevrate'] = (fct_value['h_line'] - fct_value['l_line']) / (close * 4)
        
        # 3. SARæŒ‡æ ‡
        fct_value['sar_index'] = ta.SAR(high, low)
        fct_value['sar_close'] = (fct_value['sar_index'] - close) / close
        
        # 4. AroonæŒ‡æ ‡
        fct_value['aroon_index'] = ta.AROONOSC(high, low, timeperiod=14)
        
        # 5. CCIæŒ‡æ ‡
        fct_value['cci_14'] = ta.CCI(close, high, low, timeperiod=14)
        fct_value['cci_25'] = ta.CCI(close, high, low, timeperiod=25)
        fct_value['cci_55'] = ta.CCI(close, high, low, timeperiod=55)
        
        # 6. CMOæŒ‡æ ‡
        fct_value['cmo_14'] = ta.CMO(close, timeperiod=14)
        fct_value['cmo_25'] = ta.CMO(close, timeperiod=25)
        
        # 7. MFIæŒ‡æ ‡
        fct_value['mfi_index'] = ta.MFI(high, low, close, volume)
        
        # 8. åŠ¨é‡æŒ‡æ ‡
        fct_value['mom_14'] = ta.MOM(close, timeperiod=14)
        fct_value['mom_25'] = ta.MOM(close, timeperiod=25)
        
        # 9. PPOæŒ‡æ ‡
        fct_value['ppo_index'] = ta.PPO(close, fastperiod=12, slowperiod=26, matype=0)
        
        # 10. ADæŒ‡æ ‡
        fct_value['ad_index'] = ta.AD(high, low, close, volume)
        fct_value['ad_real'] = ta.ADOSC(high, low, close, volume, fastperiod=3, slowperiod=10)
        
        # 11. OBVæŒ‡æ ‡
        fct_value['obv_index'] = ta.OBV(close, volume)
        
        # 12. ATRæŒ‡æ ‡
        fct_value['atr_14'] = ta.ATR(high, low, close, timeperiod=14)
        fct_value['atr_25'] = ta.ATR(high, low, close, timeperiod=25)
        fct_value['atr_60'] = ta.ATR(high, low, close, timeperiod=60)
        fct_value['tr_index'] = ta.TRANGE(high, low, close)
        fct_value['tr_ma5'] = ta.MA(fct_value['tr_index'], timeperiod=5, matype=0) / close
        fct_value['tr_ma10'] = ta.MA(fct_value['tr_index'], timeperiod=10, matype=0) / close
        fct_value['tr_ma20'] = ta.MA(fct_value['tr_index'], timeperiod=20, matype=0) / close
        
        # 13. KDJæŒ‡æ ‡
        fct_value['kdj_k'], fct_value['kdj_d'] = ta.STOCH(
            high, low, close, fastk_period=9, slowk_period=5, slowk_matype=1,
            slowd_period=5, slowd_matype=1)
        fct_value['kdj_j'] = fct_value['kdj_k'] - fct_value['kdj_d']
        
        # 14. MACDæŒ‡æ ‡
        fct_value['macd_dif'], fct_value['macd_dea'], fct_value['macd_hist'] = ta.MACD(
            close, fastperiod=12, slowperiod=26, signalperiod=9)
        
        # 15. RSIæŒ‡æ ‡
        fct_value['rsi_6'] = ta.RSI(close, timeperiod=6)
        fct_value['rsi_12'] = ta.RSI(close, timeperiod=12)
        fct_value['rsi_25'] = ta.RSI(close, timeperiod=25)
        
        # å¤„ç†ç¼ºå¤±å€¼
        fct_value = fct_value.replace([np.nan], 0.0)
        
        self.factor_data = fct_value
        print(f"å› å­ç”Ÿæˆå®Œæˆï¼Œå…±ç”Ÿæˆ {len(fct_value.columns)} ä¸ªå› å­")
        return self
    
    def normalize_factors(self):
        """å› å­æ ‡å‡†åŒ–"""
        print("æ­£åœ¨è¿›è¡Œå› å­æ ‡å‡†åŒ–...")
        
        # æ‰©å±•çª—å£æ ‡å‡†åŒ–
        factors_mean = self.factor_data.cumsum() / np.arange(1, self.factor_data.shape[0] + 1)[:, np.newaxis]
        factors_std = self.factor_data.expanding().std()
        factor_value = (self.factor_data - factors_mean) / factors_std
        factor_value = factor_value.replace([np.nan], 0.0)
        factor_value = factor_value.clip(-6, 6)  # å¼‚å¸¸å€¼å¤„ç†
        
        self.factor_data = factor_value
        print("å› å­æ ‡å‡†åŒ–å®Œæˆ")
        return self
    
    def factor_selection_by_correlation(self, column_list, corr_threshold):
        """åŸºäºç›¸å…³æ€§ç­›é€‰å› å­"""
        fac_columns = column_list.copy()
        if 'return' in column_list:
            fac_columns = column_list[:-1]
        
        # åˆ›å»ºä¸´æ—¶æ•°æ®æ¡†ç”¨äºç­›é€‰
        temp_data = self.factor_data[fac_columns].copy()
        temp_data['return'] = self.raw_data['return'].values
        
        X = temp_data[fac_columns]
        y = temp_data['return']
        
        # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
        X_corr_matrix = X.corr()
        
        factor_list_1 = [i for i in X_corr_matrix.columns]
        factor_list_2 = [i for i in X_corr_matrix.columns]
        
        for i in range(0, len(factor_list_1), 1):
            fct_1 = factor_list_1[i]
            for j in range(0, i, 1):
                fct_2 = factor_list_1[j]
                corr_value = X_corr_matrix.iloc[i, j]
                if abs(corr_value) > corr_threshold:
                    corr_1 = np.corrcoef(X[fct_1], y)[0, 1]
                    corr_2 = np.corrcoef(X[fct_2], y)[0, 1]
                    if (abs(corr_1) < abs(corr_2)) and (fct_1 in factor_list_2):
                        factor_list_2.remove(fct_1)
        
        return factor_list_2
    
    def select_factors(self):
        """å› å­ç­›é€‰"""
        print("æ­£åœ¨è¿›è¡Œå› å­ç­›é€‰...")
        
        # æ·»åŠ æ”¶ç›Šç‡åˆ°å› å­æ•°æ®
        factor_data_with_return = self.factor_data.copy()
        factor_data_with_return['return'] = self.raw_data['return'].values
        
        # è·å–æ‰€æœ‰å› å­åˆ—å
        column_list = list(self.factor_data.columns)
        
        # åŸºäºç›¸å…³æ€§ç­›é€‰
        selected_factors = self.factor_selection_by_correlation(
            column_list, self.config['corr_threshold'])
        
        print(f"ç›¸å…³æ€§ç­›é€‰åå‰©ä½™ {len(selected_factors)} ä¸ªå› å­")
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šç­›é€‰é€»è¾‘ï¼Œæ¯”å¦‚åŸºäºå•å› å­è¡¨ç°ç­‰
        # ç›®å‰ä½¿ç”¨ç›¸å…³æ€§ç­›é€‰çš„ç»“æœ
        self.selected_factors = selected_factors
        
        return self
    
    def prepare_training_data(self):
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        print("æ­£åœ¨å‡†å¤‡è®­ç»ƒæ•°æ®...")
        
        # å‡†å¤‡feed_data
        self.feed_data = self.factor_data[self.selected_factors].copy()
        self.feed_data['y'] = self.raw_data['return'].values
        self.feed_data = self.feed_data.reset_index()
        
        # ç¡®å®šè®­ç»ƒé›†ç»“æŸç´¢å¼•
        train_end_date = pd.to_datetime(self.config['train_end_date'])
        mask = ((self.feed_data['timestamp'].dt.year == train_end_date.year) & 
                (self.feed_data['timestamp'].dt.month == train_end_date.month) & 
                (self.feed_data['timestamp'].dt.day == train_end_date.day))
        
        if mask.any():
            self.train_set_end_index = self.feed_data[mask].index[-1]
        else:
            # å¦‚æœæ‰¾ä¸åˆ°ç¡®åˆ‡æ—¥æœŸï¼Œä½¿ç”¨æœ€æ¥è¿‘çš„æ—¥æœŸ
            self.train_set_end_index = int(len(self.feed_data) * 0.7)  # 70%ä½œä¸ºè®­ç»ƒé›†
        
        # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        self.X_train = self.feed_data[self.selected_factors][:self.train_set_end_index].values
        self.y_train = self.feed_data['y'][:self.train_set_end_index].values.reshape(-1, 1)
        self.X_test = self.feed_data[self.selected_factors][self.train_set_end_index:].values
        self.y_test = self.feed_data['y'][self.train_set_end_index:].values.reshape(-1, 1)
        
        print(f"è®­ç»ƒé›†å¤§å°: {self.X_train.shape}")
        print(f"æµ‹è¯•é›†å¤§å°: {self.X_test.shape}")
        
        return self
    
    def train_models(self):
        """è®­ç»ƒå¤šä¸ªæ¨¡å‹"""
        print("æ­£åœ¨è®­ç»ƒæ¨¡å‹...")
        
        # 1. çº¿æ€§å›å½’
        print("è®­ç»ƒçº¿æ€§å›å½’æ¨¡å‹...")
        lr_model = LinearRegression(fit_intercept=True)
        lr_model.fit(self.X_train, self.y_train)
        self.models['LinearRegression'] = lr_model
        
        # 2. Ridgeå›å½’
        print("è®­ç»ƒRidgeå›å½’æ¨¡å‹...")
        ridge_model = Ridge(alpha=0.2, fit_intercept=True)
        ridge_model.fit(self.X_train, self.y_train)
        self.models['Ridge'] = ridge_model
        
        # 3. Lassoå›å½’
        print("è®­ç»ƒLassoå›å½’æ¨¡å‹...")
        lasso_model = LassoCV(fit_intercept=True)
        lasso_model.fit(self.X_train, self.y_train.ravel())
        self.models['Lasso'] = lasso_model
        
        # 4. XGBoost
        print("è®­ç»ƒXGBoostæ¨¡å‹...")
        X_train_df = pd.DataFrame(self.X_train, columns=self.selected_factors)
        y_train_series = pd.Series(self.y_train.ravel())
        X_test_df = pd.DataFrame(self.X_test, columns=self.selected_factors)
        y_test_series = pd.Series(self.y_test.ravel())
        
        xgb_model = XGBRegressor(
            max_depth=3,
            learning_rate=0.1,
            n_estimators=100,
            objective='reg:squarederror',
            random_state=0,
            early_stopping_rounds=20
        )
        
        xgb_model.fit(
            X_train_df, y_train_series,
            eval_set=[(X_test_df, y_test_series)],
            verbose=False
        )
        
        self.models['XGBoost'] = xgb_model
        
        # 5. LightGBM
        print("è®­ç»ƒLightGBMæ¨¡å‹...")
        lgb_params = {
            'objective': 'regression',
            'metric': 'rmse',
            'boosting': 'gbdt',
            'learning_rate': 0.054,
            'max_depth': 3,
            'num_leaves': 32,
            'min_data_in_leaf': 50,
            'feature_fraction': 0.5,
            'bagging_fraction': 0.5,
            'lambda_l1': 0.05,
            'lambda_l2': 120,
            'verbose': -1
        }
        
        lgb_train = lgb.Dataset(X_train_df, y_train_series)
        lgb_val = lgb.Dataset(X_test_df, y_test_series, reference=lgb_train)
        
        lgb_model = lgb.train(
                lgb_params,
                lgb_train,
                num_boost_round=500,
                valid_sets=lgb_val,
                callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)]
        )
        
        self.models['LightGBM'] = lgb_model
        
        print("æ‰€æœ‰æ¨¡å‹è®­ç»ƒå®Œæˆ")
        return self
    
    def make_predictions(self, weight_method='equal'):
        """ç”Ÿæˆé¢„æµ‹
        
        Args:
            weight_method (str): æƒé‡è®¡ç®—æ–¹æ³•ï¼Œå¯é€‰ 'equal'ï¼ˆç­‰æƒé‡ï¼‰æˆ– 'sharpe'ï¼ˆåŸºäºå¤æ™®æ¯”ç‡ï¼‰
        """
        print("æ­£åœ¨ç”Ÿæˆé¢„æµ‹...")
        
        # å­˜å‚¨æ‰€æœ‰æ¨¡å‹çš„é¢„æµ‹ç»“æœ
        all_train_predictions = []
        all_test_predictions = []
        model_names = []
        
        for model_name, model in self.models.items():
            if model_name == 'LightGBM':
                # LightGBMéœ€è¦ç‰¹æ®Šå¤„ç†
                train_pred = model.predict(self.X_train)
                test_pred = model.predict(self.X_test)
            else:
                train_pred = model.predict(self.X_train).flatten()
                test_pred = model.predict(self.X_test).flatten()
            
            # å­˜å‚¨å•ä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœ
            self.predictions[model_name] = {
                'train': train_pred,
                'test': test_pred
            }
            
            # æ”¶é›†æ‰€æœ‰æ¨¡å‹çš„é¢„æµ‹ç»“æœç”¨äºç»„åˆ
            all_train_predictions.append(train_pred)
            all_test_predictions.append(test_pred)
            model_names.append(model_name)
        
        # è®¡ç®—ç»„åˆæƒé‡
        if weight_method == 'equal':
            # ç­‰æƒé‡ç»„åˆ
            weights = {name: 1.0/len(model_names) for name in model_names}
        elif weight_method == 'sharpe':
            # åŸºäºå¤æ™®æ¯”ç‡çš„æƒé‡
            # å…ˆå¯¹æ¯ä¸ªæ¨¡å‹è¿›è¡Œå›æµ‹ä»¥è·å–å¤æ™®æ¯”ç‡
            sharpe_ratios = {}
            for model_name in model_names:
                # è·å–æ—¶é—´ç´¢å¼•
                train_time = self.feed_data['timestamp'][:self.train_set_end_index].values
                test_time = self.feed_data['timestamp'][self.train_set_end_index:].values
                
                # è®¡ç®—è®­ç»ƒé›†è¡¨ç°
                train_ret_frame = self.calculate_portfolio_performance(
                    self.predictions[model_name]['train'], train_time, 'train')
                
                # è®¡ç®—æµ‹è¯•é›†è¡¨ç°
                test_ret_frame = self.calculate_portfolio_performance(
                    self.predictions[model_name]['test'], test_time, 'test')
                
                # è®¡ç®—å¤æ™®æ¯”ç‡
                train_metrics = self.calculate_performance_metrics(train_ret_frame)
                test_metrics = self.calculate_performance_metrics(test_ret_frame)
                
                # ä½¿ç”¨æµ‹è¯•é›†å¤æ™®æ¯”ç‡çš„ç»å¯¹å€¼ä½œä¸ºæƒé‡
                sharpe_ratios[model_name] = abs(test_metrics['å¤æ™®æ¯”ç‡'])
            
            # è®¡ç®—æƒé‡ï¼ˆç¡®ä¿æƒé‡å’Œä¸º1ï¼‰
            total_sharpe = sum(sharpe_ratios.values())
            if total_sharpe > 0:
                weights = {name: sharpe/total_sharpe for name, sharpe in sharpe_ratios.items()}
            else:
                # å¦‚æœæ‰€æœ‰å¤æ™®æ¯”ç‡éƒ½ä¸º0ï¼Œä½¿ç”¨ç­‰æƒé‡
                weights = {name: 1.0/len(model_names) for name in model_names}
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æƒé‡è®¡ç®—æ–¹æ³•: {weight_method}")
        
        # å­˜å‚¨æƒé‡ä¿¡æ¯
        self.ensemble_weights = weights
        
        # è®¡ç®—åŠ æƒç»„åˆé¢„æµ‹
        ensemble_train_pred = np.zeros_like(all_train_predictions[0])
        ensemble_test_pred = np.zeros_like(all_test_predictions[0])
        
        for i, model_name in enumerate(model_names):
            ensemble_train_pred += weights[model_name] * all_train_predictions[i]
            ensemble_test_pred += weights[model_name] * all_test_predictions[i]
        
        # æ·»åŠ ç»„åˆæ¨¡å‹é¢„æµ‹ç»“æœ
        self.predictions['Ensemble'] = {
            'train': ensemble_train_pred,
            'test': ensemble_test_pred
        }
        
        print("é¢„æµ‹ç”Ÿæˆå®Œæˆ")
        print(f"å·²ç”Ÿæˆ {len(self.predictions)} ä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœï¼ŒåŒ…æ‹¬{weight_method}æƒé‡ç»„åˆæ¨¡å‹")
        return self
    
    def get_ensemble_weights(self):
        """è·å–å„ä¸ªæ¨¡å‹åœ¨ç»„åˆä¸­çš„æƒé‡"""
        if 'Ensemble' not in self.predictions:
            print("è¯·å…ˆè¿è¡Œmake_predictionsç”Ÿæˆé¢„æµ‹ç»“æœ")
            return None
        
        if not hasattr(self, 'ensemble_weights'):
            print("æœªæ‰¾åˆ°æƒé‡ä¿¡æ¯")
            return None
        
        # æ‰“å°æƒé‡ä¿¡æ¯
        print("\næ¨¡å‹ç»„åˆæƒé‡:")
        for model_name, weight in self.ensemble_weights.items():
            print(f"{model_name}: {weight:.2%}")
        
        return self.ensemble_weights
    
    def save_models(self):
        """ä¿å­˜æ¨¡å‹"""
        print("æ­£åœ¨ä¿å­˜æ¨¡å‹...")
        
        save_path = self.config['model_save_path']
        for model_name, model in self.models.items():
            if model_name == 'LightGBM':
                model.save_model(f"{save_path}/lgb_model.txt")
            else:
                joblib.dump(model, f"{save_path}/{model_name.lower()}_model.pkl")
        
        print("æ¨¡å‹ä¿å­˜å®Œæˆ")
        return self
    
    def generate_etime_close_data(self, bgn_date, end_date, index_code='510050', frequency='15'):
        """ç”Ÿæˆæ—¶é—´-ä»·æ ¼æ•°æ®"""
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æ•°æ®
        mask = ((self.raw_data.index >= pd.to_datetime(bgn_date)) & 
                (self.raw_data.index <= pd.to_datetime(end_date)))
        
        result = self.raw_data[mask][['close']].reset_index()
        result.columns = ['etime', 'close']
        result['tdate'] = result['etime'].dt.date
        
        return result
    
    def calculate_portfolio_performance(self, predictions, time_index, data_type='test'):
        """è®¡ç®—ç»„åˆè¡¨ç°"""
        position_size = self.config['position_size']
        clip_num = self.config['clip_num']
        
        # è·å–å¯¹åº”æ—¶é—´æ®µçš„ä»·æ ¼æ•°æ®
        if data_type == 'train':
            begin_date = str(time_index[0])
            end_date = str(time_index[-1])
        else:
            begin_date = str(time_index[0])
            end_date = str(time_index[-1])
        
        ret_frame = self.generate_etime_close_data(begin_date, end_date)
        
        # æ˜ å°„ä»“ä½
        ret_frame['position'] = [(i / 0.0005) * position_size for i in predictions]
        ret_frame['position'] = ret_frame['position'].clip(-clip_num, clip_num)
        
        # è®¡ç®—æŒä»“å‡€å€¼
        ret_frame.loc[0, 'æŒä»“å‡€å€¼'] = 1
        
        for i in range(0, len(ret_frame), 1):
            if i == 0 or ret_frame.loc[i-1, 'position'] == 0:
                ret_frame.loc[i, 'æŒä»“å‡€å€¼'] = 1
            else:
                close_2 = ret_frame.loc[i, 'close']
                close_1 = ret_frame.loc[i-1, 'close']
                position = abs(ret_frame.loc[i-1, 'position'])
                
                if ret_frame.loc[i-1, 'position'] > 0:  # å¤šä»“
                    ret_frame.loc[i, 'æŒä»“å‡€å€¼'] = 1 * (close_2 / close_1) * position + 1 * (1 - position)
                elif ret_frame.loc[i-1, 'position'] < 0:  # ç©ºä»“
                    ret_frame.loc[i, 'æŒä»“å‡€å€¼'] = 1 * (1 - (close_2 / close_1 - 1)) * position + 1 * (1 - position)
        
        # è®¡ç®—ç´¯è®¡å‡€å€¼
        ret_frame.loc[0, 'æŒä»“å‡€å€¼ï¼ˆç´¯è®¡ï¼‰'] = 1
        for i in range(1, len(ret_frame)):
            ret_frame.loc[i, 'æŒä»“å‡€å€¼ï¼ˆç´¯è®¡ï¼‰'] = (ret_frame.loc[i-1, 'æŒä»“å‡€å€¼ï¼ˆç´¯è®¡ï¼‰'] * 
                                                ret_frame.loc[i, 'æŒä»“å‡€å€¼'])
        
        return ret_frame
    
    def calculate_performance_metrics(self, ret_frame):
        """è®¡ç®—ç»©æ•ˆæŒ‡æ ‡"""
        fixed_return = self.config['fixed_return']
        
        # åŸºæœ¬æ”¶ç›ŠæŒ‡æ ‡
        start_index = ret_frame.index[0]
        end_index = ret_frame.index[-1]
        
        net_value_start = ret_frame.loc[start_index, 'æŒä»“å‡€å€¼ï¼ˆç´¯è®¡ï¼‰']
        net_value_end = ret_frame.loc[end_index, 'æŒä»“å‡€å€¼ï¼ˆç´¯è®¡ï¼‰']
        total_return = net_value_end / net_value_start - 1
        
        # å¹´åŒ–æ”¶ç›Šç‡
        date_list = ret_frame['tdate'].unique()
        run_days = len(date_list)
        annual_return = math.pow(1 + total_return, 252 / run_days) - 1
        
        # è®¡ç®—æ—¥åº¦æ”¶ç›Šç‡ç”¨äºæ³¢åŠ¨ç‡å’Œå¤æ™®æ¯”ç‡
        daily_nav = ret_frame.groupby('tdate')['æŒä»“å‡€å€¼ï¼ˆç´¯è®¡ï¼‰'].last()
        daily_returns = daily_nav.pct_change().dropna()
        
        # å¹´åŒ–æ³¢åŠ¨ç‡
        annual_volatility = math.sqrt(252) * daily_returns.std()
        
        # å¤æ™®æ¯”ç‡
        sharpe_ratio = (annual_return - fixed_return) / annual_volatility if annual_volatility > 0 else 0
        
        # æœ€å¤§å›æ’¤
        cumulative_nav = daily_nav.values
        running_max = np.maximum.accumulate(cumulative_nav)
        drawdown = (running_max - cumulative_nav) / running_max
        max_drawdown = np.max(drawdown)
        
        # å¡å°”ç›æ¯”ç‡
        calmar_ratio = (annual_return - fixed_return) / max_drawdown if max_drawdown > 0 else 0
        
        # èƒœç‡
        win_rate = (daily_returns > 0).mean()
        
        return {
            'æ€»æ”¶ç›Š': total_return,
            'å¹´åŒ–æ”¶ç›Š': annual_return,
            'å¹´åŒ–æ³¢åŠ¨ç‡': annual_volatility,
            'å¤æ™®æ¯”ç‡': sharpe_ratio,
            'æœ€å¤§å›æ’¤ç‡': max_drawdown,
            'å¡å°”ç›æ¯”ç‡': calmar_ratio,
            'èƒœç‡': win_rate,
            'äº¤æ˜“æ¬¡æ•°': len(ret_frame)
        }
    
    def backtest(self, model_name='LightGBM'):
        """å›æµ‹æŒ‡å®šæ¨¡å‹"""
        print(f"æ­£åœ¨å›æµ‹ {model_name} æ¨¡å‹...")
        
        if model_name not in self.predictions:
            raise ValueError(f"æ¨¡å‹ {model_name} çš„é¢„æµ‹ç»“æœä¸å­˜åœ¨")
        
        # è·å–æ—¶é—´ç´¢å¼•
        train_time = self.feed_data['timestamp'][:self.train_set_end_index].values
        test_time = self.feed_data['timestamp'][self.train_set_end_index:].values
        
        # è®¡ç®—è®­ç»ƒé›†è¡¨ç°
        train_ret_frame = self.calculate_portfolio_performance(
            self.predictions[model_name]['train'], train_time, 'train')
        
        # è®¡ç®—æµ‹è¯•é›†è¡¨ç°
        test_ret_frame = self.calculate_portfolio_performance(
            self.predictions[model_name]['test'], test_time, 'test')
        
        # è®¡ç®—ç»©æ•ˆæŒ‡æ ‡
        train_metrics = self.calculate_performance_metrics(train_ret_frame)
        test_metrics = self.calculate_performance_metrics(test_ret_frame)
        
        self.backtest_results[model_name] = {
            'train_frame': train_ret_frame,
            'test_frame': test_ret_frame,
            'train_metrics': train_metrics,
            'test_metrics': test_metrics
        }
        
        print(f"{model_name} å›æµ‹å®Œæˆ")
        print(f"æ ·æœ¬å†…å¤æ™®æ¯”ç‡: {train_metrics['å¤æ™®æ¯”ç‡']:.4f}")
        print(f"æ ·æœ¬å¤–å¤æ™®æ¯”ç‡: {test_metrics['å¤æ™®æ¯”ç‡']:.4f}")
        
        return self
    
    def backtest_all_models(self):
        """å›æµ‹æ‰€æœ‰æ¨¡å‹"""
        print("æ­£åœ¨å›æµ‹æ‰€æœ‰æ¨¡å‹...")
        
        for model_name in self.predictions.keys():
            self.backtest(model_name)
        
        return self
    
    def plot_results(self, model_name='Ensemble', close_fig=False):
        """ç»˜åˆ¶å›æµ‹ç»“æœ
        
        Args:
            model_name (str): æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸º 'Ensemble'
            close_fig (bool): æ˜¯å¦å…³é—­å›¾å½¢ï¼Œé»˜è®¤ä¸º False
        """
        if model_name not in self.backtest_results:
            print(f"æ¨¡å‹ {model_name} çš„å›æµ‹ç»“æœä¸å­˜åœ¨")
            return
        
        test_frame = self.backtest_results[model_name]['test_frame']
        test_metrics = self.backtest_results[model_name]['test_metrics']
        
        # åˆ›å»ºå›¾è¡¨
        plt.figure(figsize=(14, 8))
        
        # è®¾ç½®é¢œè‰²å’Œçº¿å‹
        if model_name == 'Ensemble':
            color = 'r'  # ç»„åˆæ¨¡å‹ç”¨çº¢è‰²
            linewidth = 2.5
            linestyle = '-'
            title_prefix = 'ç­‰æƒé‡ç»„åˆæ¨¡å‹'
        else:
            color = 'b'  # å…¶ä»–æ¨¡å‹ç”¨è“è‰²
            linewidth = 2
            linestyle = '-'
            title_prefix = model_name
        
        # ç»˜åˆ¶å‡€å€¼æ›²çº¿
        plt.plot(test_frame['etime'], test_frame['æŒä»“å‡€å€¼ï¼ˆç´¯è®¡ï¼‰'], 
                color=color, linestyle=linestyle, linewidth=linewidth,
                label=f'{title_prefix} æµ‹è¯•é›†å‡€å€¼æ›²çº¿')
        
        # è®¾ç½®å›¾è¡¨æ ‡é¢˜å’Œæ ‡ç­¾
        title = f'{title_prefix} å›æµ‹ç»“æœ'
        plt.title(title, fontsize=16, fontweight='bold', pad=20)
        plt.xlabel('æ—¶é—´', fontsize=12)
        plt.ylabel('ç´¯è®¡å‡€å€¼', fontsize=12)
        
        # æ·»åŠ æ€§èƒ½æŒ‡æ ‡åˆ°å›¾ä¾‹
        if model_name == 'Ensemble':
            # è·å–ç»„åˆæ¨¡å‹çš„æƒé‡ä¿¡æ¯
            weights = self.get_ensemble_weights()
            weight_info = "\n".join([f"{name}: {w:.1%}" for name, w in weights.items()])
            
            legend_text = (f'{title_prefix} æµ‹è¯•é›†å‡€å€¼æ›²çº¿\n'
                          f'å¹´åŒ–æ”¶ç›Š: {test_metrics["å¹´åŒ–æ”¶ç›Š"]:.2%}\n'
                          f'å¤æ™®æ¯”ç‡: {test_metrics["å¤æ™®æ¯”ç‡"]:.3f}\n'
                          f'æœ€å¤§å›æ’¤: {test_metrics["æœ€å¤§å›æ’¤ç‡"]:.2%}\n'
                          f'æ¨¡å‹æƒé‡:\n{weight_info}')
        else:
            legend_text = (f'{title_prefix} æµ‹è¯•é›†å‡€å€¼æ›²çº¿\n'
                          f'å¹´åŒ–æ”¶ç›Š: {test_metrics["å¹´åŒ–æ”¶ç›Š"]:.2%}\n'
                          f'å¤æ™®æ¯”ç‡: {test_metrics["å¤æ™®æ¯”ç‡"]:.3f}\n'
                          f'æœ€å¤§å›æ’¤: {test_metrics["æœ€å¤§å›æ’¤ç‡"]:.2%}')
        
        plt.plot([], [], ' ', label=legend_text)
        plt.legend(loc='upper left', fontsize=10)
        
        # è®¾ç½®ç½‘æ ¼å’Œæ ·å¼
        plt.grid(True, alpha=0.3, linestyle='--')
        plt.xticks(rotation=45)
        
        # è®¾ç½®yè½´æ ¼å¼
        plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:.3f}'))
        
        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout()
        
        # å¦‚æœæ˜¯Macç³»ç»Ÿä¸”å­—ä½“æœ‰é—®é¢˜ï¼Œæ˜¾ç¤ºæç¤º
        if platform.system() == 'Darwin':
            try:
                # æµ‹è¯•ä¸­æ–‡æ˜¾ç¤º
                test_fig = plt.figure(figsize=(1, 1))
                test_fig.text(0.5, 0.5, 'æµ‹è¯•ä¸­æ–‡', fontsize=1)
                plt.close(test_fig)
            except:
                print("æç¤ºï¼šå¦‚æœå›¾è¡¨ä¸­çš„ä¸­æ–‡æ˜¾ç¤ºä¸ºæ–¹æ¡†ï¼Œè¯·å®‰è£…ä¸­æ–‡å­—ä½“")
        
        if close_fig:
            plt.show()
        else:
            plt.show(block=False)  # éé˜»å¡æ¨¡å¼æ˜¾ç¤ºå›¾å½¢
        
        return self
    
    def get_performance_summary(self):
        """è·å–æ‰€æœ‰æ¨¡å‹çš„ç»©æ•ˆæ±‡æ€»"""
        if not self.backtest_results:
            print("è¯·å…ˆè¿è¡Œå›æµ‹")
            return None
        
        summary_data = []
        
        for model_name, results in self.backtest_results.items():
            train_metrics = results['train_metrics']
            test_metrics = results['test_metrics']
            
            summary_data.append({
                'æ¨¡å‹': model_name,
                'æ ·æœ¬å†…å¹´åŒ–æ”¶ç›Š': train_metrics['å¹´åŒ–æ”¶ç›Š'],
                'æ ·æœ¬å†…å¤æ™®æ¯”ç‡': train_metrics['å¤æ™®æ¯”ç‡'],
                'æ ·æœ¬å†…æœ€å¤§å›æ’¤': train_metrics['æœ€å¤§å›æ’¤ç‡'],
                'æ ·æœ¬å¤–å¹´åŒ–æ”¶ç›Š': test_metrics['å¹´åŒ–æ”¶ç›Š'],
                'æ ·æœ¬å¤–å¤æ™®æ¯”ç‡': test_metrics['å¤æ™®æ¯”ç‡'],
                'æ ·æœ¬å¤–æœ€å¤§å›æ’¤': test_metrics['æœ€å¤§å›æ’¤ç‡']
            })
        
        summary_df = pd.DataFrame(summary_data)
        summary_df = summary_df.round(4)
        
        print("æ¨¡å‹ç»©æ•ˆæ±‡æ€»:")
        print(summary_df.to_string(index=False))
        
        return summary_df
    
    def run_full_pipeline(self):
        """è¿è¡Œå®Œæ•´çš„ç­–ç•¥æµç¨‹"""
        print("å¼€å§‹è¿è¡Œå®Œæ•´çš„é‡åŒ–ç­–ç•¥æµç¨‹...")
        
        # æ‰§è¡Œå®Œæ•´æµç¨‹
        (self.load_data()
         .generate_factors()
         .normalize_factors()
         .select_factors()
        #  .prepare_training_data()
        #  .train_models()
        #  .make_predictions(weight_method=self.config['weight_method'])
        #  .save_models()
        #  .backtest_all_models()
         )
        
        # æ˜¾ç¤ºæ¨¡å‹ç»„åˆæƒé‡
        # self.get_ensemble_weights()
        
        # æ˜¾ç¤ºæ‰€æœ‰æ¨¡å‹çš„ç»©æ•ˆæ±‡æ€»
        # summary_df = self.get_performance_summary()
        
        print("ç­–ç•¥æµç¨‹æ‰§è¡Œå®Œæˆï¼")
        return self

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # è·å–å½“å‰è¿è¡Œç›®å½•
    current_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))  # è·å–å·¥ç¨‹æ ¹ç›®å½•
    data_dir = os.path.join(current_dir, 'data')  # æŒ‡å‘å·¥ç¨‹æ ¹ç›®å½•ä¸‹çš„ data ç›®å½•
    models_dir = os.path.join(data_dir, 'models')  # æŒ‡å‘ data/models ç›®å½•

    # ç¡®ä¿ models ç›®å½•å­˜åœ¨
    # os.makedirs(models_dir, exist_ok=True)

    # é…ç½®å‚æ•°
    config = {
        'return_period': 1,
        'corr_threshold': 0.3,
        'sharpe_threshold': 0.2,
        'train_end_date': '2016-12-30',
        'position_size': 1.0,
        'clip_num': 2.0,
        'fixed_return': 0.0,
        'fees_rate': 0.004,
        'weight_method': 'sharpe', # æƒé‡æ–¹æ³•ï¼Œå¯é€‰ 'equal' æˆ– 'sharpe' 
        'model_save_path': models_dir  # ä½¿ç”¨ data/models ç›®å½•ä½œä¸ºæ¨¡å‹ä¿å­˜è·¯å¾„
    }
    
    # åˆ›å»ºç­–ç•¥å®ä¾‹
    strategy = QuantTradingStrategy(
        data_path=os.path.join(data_dir, 'courses', '510050.SH_15.pkl'),  # ä½¿ç”¨ data/courses ç›®å½•ä¸‹çš„æ•°æ®æ–‡ä»¶
        config=config
    )
    
    # è¿è¡Œå®Œæ•´æµç¨‹ï¼Œä½¿ç”¨åŸºäºå¤æ™®æ¯”ç‡çš„æƒé‡
    strategy.run_full_pipeline()

    # ç»˜åˆ¶ç»„åˆæ¨¡å‹çš„ç»“æœ
    strategy.plot_results('Ensemble')
    
    # ä¿æŒå›¾å½¢çª—å£æ˜¾ç¤ºï¼Œç›´åˆ°ç”¨æˆ·æ‰‹åŠ¨å…³é—­
    plt.show(block=True)