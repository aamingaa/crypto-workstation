"""
Bar çº§ç‰¹å¾æ»šåŠ¨ç»Ÿè®¡æå–å™¨
å¯¹å·²èšåˆçš„ bar çº§ç‰¹å¾è¿›è¡Œæ—¶é—´åºåˆ—ç»Ÿè®¡ï¼Œæ•è·åŠ¨æ€å˜åŒ–æ¨¡å¼
"""
import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Any
from scipy.stats import linregress


class RollingAggregator:
    """Bar çº§ç‰¹å¾çš„æ»šåŠ¨ç»Ÿè®¡æå–å™¨"""
    
    def __init__(self, feature_extractor=None, windows: Optional[List[int]] = None):
        """
        å‚æ•°:
            feature_extractor: MicrostructureFeatureExtractor å®ä¾‹ï¼ˆå¤ç”¨ç°æœ‰ç‰¹å¾æå–å™¨ï¼‰
            windows: æ»šåŠ¨çª—å£åˆ—è¡¨ï¼ˆä»¥ bar ä¸ºå•ä½ï¼‰
                    None åˆ™ä½¿ç”¨å•ä¸€çª—å£ï¼ˆç”± extract æ–¹æ³•æŒ‡å®šï¼‰
        """
        self.feature_extractor = feature_extractor
        self.windows = windows
    
    def extract_bar_level_features(self, bars: pd.DataFrame, 
                                   ctx, 
                                   bar_idx: int) -> Dict[str, float]:
        """æå–å•ä¸ª bar çš„å¾®è§‚ç»“æ„ç‰¹å¾ï¼ˆå¤ç”¨ç°æœ‰ç‰¹å¾æå–å™¨ï¼‰
        
        å‚æ•°:
            bars: æ‰€æœ‰ bars çš„ DataFrame
            ctx: TradesContext
            bar_idx: å½“å‰ bar çš„ç´¢å¼•
        
        è¿”å›:
            è¯¥ bar çš„ç‰¹å¾å­—å…¸
        """
        if bar_idx >= len(bars):
            return {}
        
        bar = bars.iloc[bar_idx]
        
        # è·å–è¯¥ bar çš„æ—¶é—´èŒƒå›´
        start_ts = pd.to_datetime(bar['start_time'])
        end_ts = pd.to_datetime(bar['end_time'])
        
        # ä½¿ç”¨ç°æœ‰çš„ç‰¹å¾æå–å™¨æå–è¯¥ bar çš„ç‰¹å¾
        if self.feature_extractor is not None:
            features = self.feature_extractor.extract_from_context(
                ctx=ctx,
                start_ts=start_ts,
                end_ts=end_ts,
                bars=bars,
                bar_window_start_idx=bar_idx,
                bar_window_end_idx=bar_idx
            )
            
            # ç»™ç‰¹å¾åŠ ä¸Š 'bar_' å‰ç¼€ä»¥åŒºåˆ†å• bar ç‰¹å¾å’Œçª—å£ç‰¹å¾
            bar_features = {f'bar_{k}': v for k, v in features.items()}
            return bar_features
        else:
            # å¦‚æœæ²¡æœ‰æä¾›ç‰¹å¾æå–å™¨ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬ï¼ˆå‘åå…¼å®¹ï¼‰
            return self._extract_bar_level_features_simple(bars, ctx, bar_idx)
    
    def _extract_bar_level_features_simple(self, bars: pd.DataFrame, 
                                          ctx, 
                                          bar_idx: int) -> Dict[str, float]:
        """ç®€åŒ–ç‰ˆ bar çº§ç‰¹å¾æå–ï¼ˆå‘åå…¼å®¹ï¼‰"""
        bar = bars.iloc[bar_idx]
        s = int(bar['start_trade_idx'])
        e = int(bar['end_trade_idx']) + 1
        
        if e - s <= 0:
            return {}
        
        features = {}
        
        # 1. æ³¢åŠ¨ç‡ç‰¹å¾
        rv = self._sum_range(ctx.csum_ret2, s, e)
        bpv = self._sum_range(ctx.csum_bpv, s, e)
        features['bar_rv'] = rv
        features['bar_bpv'] = bpv
        features['bar_jump'] = max(rv - bpv, 0.0) if (np.isfinite(rv) and np.isfinite(bpv)) else 0.0
        
        # 2. è®¢å•æµç‰¹å¾ï¼ˆåˆ†æ¡¶ï¼‰
        dv = ctx.quote[s:e]
        sign = ctx.sign[s:e]
        
        if len(dv) >= 5:
            low_q = np.quantile(dv, 0.2)
            high_q = np.quantile(dv, 0.8)
            
            small_mask = dv <= low_q
            large_mask = dv >= high_q
            
            features['bar_small_signed_dollar'] = float(np.sum(sign[small_mask] * dv[small_mask]))
            features['bar_large_signed_dollar'] = float(np.sum(sign[large_mask] * dv[large_mask]))
            features['bar_small_count'] = int(np.sum(small_mask))
            features['bar_large_count'] = int(np.sum(large_mask))
            
            # VPIN è¿‘ä¼¼
            features['bar_vpin'] = self._calculate_vpin(dv, sign, bins=10)
        else:
            features['bar_small_signed_dollar'] = 0.0
            features['bar_large_signed_dollar'] = 0.0
            features['bar_small_count'] = 0
            features['bar_large_count'] = 0
            features['bar_vpin'] = 0.0
        
        # 3. ä»·æ ¼è·¯å¾„ç‰¹å¾
        if e - s >= 2:
            prices = ctx.price[s:e]
            features['bar_hl_ratio'] = float((np.max(prices) - np.min(prices)) / (np.mean(prices) + 1e-12))
        else:
            features['bar_hl_ratio'] = 0.0
        
        # 4. æˆäº¤é‡ç‰¹å¾
        features['bar_signed_volume'] = self._sum_range(ctx.csum_signed_qty, s, e)
        features['bar_volume'] = self._sum_range(ctx.csum_qty, s, e)
        
        return features
    
    def _get_statistics_for_feature(self, feature_name: str) -> List[str]:
        """æ ¹æ®ç‰¹å¾ç±»å‹è¿”å›éœ€è¦è®¡ç®—çš„ç»Ÿè®¡é‡åˆ—è¡¨
        
        å‚æ•°:
            feature_name: ç‰¹å¾åç§°
        
        è¿”å›:
            ç»Ÿè®¡é‡åç§°åˆ—è¡¨
        """
        feat_lower = feature_name.lower()
        
        # â­â­â­â­â­ Tier 1: æ ¸å¿ƒæ³¢åŠ¨ç‡ç‰¹å¾ï¼ˆæœ€é‡è¦ï¼Œå…¨å¥—ç»Ÿè®¡ï¼‰
        if any(kw in feat_lower for kw in ['rv', 'bpv', 'jump', 'volatility']):
            return ['mean', 'std', 'min', 'max', 'trend', 'slope', 
                   'momentum', 'zscore', 'quantile', 'acceleration', 'autocorr']
        
        # â­â­â­â­â­ Tier 1: æ ¸å¿ƒè®¢å•æµç‰¹å¾ï¼ˆVPINï¼Œå…³é”®æŒ‡æ ‡ï¼‰
        elif 'vpin' in feat_lower:
            return ['mean', 'std', 'trend', 'slope', 'zscore', 
                   'momentum', 'quantile', 'acceleration']
        
        # â­â­â­â­ Tier 2: è®¢å•æµé‡‘é¢ç‰¹å¾ï¼ˆè¶‹åŠ¿+ä½ç½®ï¼‰
        elif any(kw in feat_lower for kw in ['signed_dollar', 'signed_quote', 
                                               'buy_dollar', 'sell_dollar']):
            return ['mean', 'std', 'trend', 'zscore', 'momentum', 'quantile']
        
        # â­â­â­â­ Tier 2: å†²å‡»/æµåŠ¨æ€§ç‰¹å¾
        elif any(kw in feat_lower for kw in ['impact', 'lambda', 'amihud', 
                                               'kyle', 'hasbrouck']):
            return ['mean', 'std', 'trend', 'zscore', 'quantile']
        
        # â­â­â­ Tier 3: åŠ¨é‡/åè½¬ç‰¹å¾
        elif any(kw in feat_lower for kw in ['momentum', 'reversion', 
                                               'dp_short', 'dp_zscore']):
            return ['mean', 'trend', 'zscore', 'momentum']
        
        # â­â­â­ Tier 3: ä»·æ ¼è·¯å¾„ç‰¹å¾
        elif any(kw in feat_lower for kw in ['hl_ratio', 'amplitude', 
                                               'comovement', 'vwap_deviation']):
            return ['mean', 'std', 'trend', 'zscore']
        
        # â­â­ Tier 4: è®¡æ•°/å¼ºåº¦ç‰¹å¾ï¼ˆåŸºç¡€ç»Ÿè®¡ï¼‰
        elif any(kw in feat_lower for kw in ['count', 'intensity', 'arrival', 
                                               'trades', 'duration']):
            return ['mean', 'std', 'trend']
        
        # â­â­ Tier 4: æˆäº¤é‡ç‰¹å¾
        elif any(kw in feat_lower for kw in ['volume', 'qty']):
            return ['mean', 'std', 'trend']
        
        # â­ Tier 5: å…¶ä»–ç‰¹å¾ï¼ˆæœ€å°ç»Ÿè®¡é›†ï¼‰
        else:
            return ['mean', 'trend', 'zscore']
    
    def extract_rolling_statistics(self, bar_features: pd.DataFrame, 
                                   window: int,
                                   current_idx: int) -> Dict[str, float]:
        """å¯¹ bar çº§ç‰¹å¾åºåˆ—è¿›è¡Œæ»šåŠ¨ç»Ÿè®¡ï¼ˆæ™ºèƒ½é€‰æ‹©ç»Ÿè®¡é‡ï¼‰
        
        å‚æ•°:
            bar_features: åŒ…å« bar çº§ç‰¹å¾çš„ DataFrame
            window: æ»šåŠ¨çª—å£å¤§å°ï¼ˆbar æ•°é‡ï¼‰
            current_idx: å½“å‰é¢„æµ‹çš„ bar ç´¢å¼•
        
        è¿”å›:
            æ»šåŠ¨ç»Ÿè®¡ç‰¹å¾å­—å…¸
        """
        if current_idx < window:
            return {}
        
        window_start = current_idx - window
        window_end = current_idx
        
        # æå–çª—å£æ•°æ®
        window_data = bar_features.iloc[window_start:window_end]
        
        if len(window_data) < window:
            return {}
        
        features = {}
        
        # ğŸ”¥ è‡ªåŠ¨è¯†åˆ«æ‰€æœ‰ bar_ å¼€å¤´çš„æ•°å€¼ç‰¹å¾ï¼ˆè€Œä¸æ˜¯ç¡¬ç¼–ç åˆ—è¡¨ï¼‰
        stat_features = [col for col in window_data.columns 
                        if col.startswith('bar_') and col != 'bar_id'
                        and pd.api.types.is_numeric_dtype(window_data[col])]
        
        if not stat_features:
            # å¦‚æœæ²¡æœ‰ bar_ å‰ç¼€çš„ç‰¹å¾ï¼Œå°è¯•ä½¿ç”¨æ‰€æœ‰æ•°å€¼åˆ—
            stat_features = [col for col in window_data.columns 
                           if pd.api.types.is_numeric_dtype(window_data[col])]
        
        # å¯¹æ¯ä¸ªç‰¹å¾è¿›è¡Œæ»šåŠ¨ç»Ÿè®¡ï¼ˆæ ¹æ®ç±»å‹æ™ºèƒ½é€‰æ‹©ç»Ÿè®¡é‡ï¼‰
        for feat in stat_features:
            if feat not in window_data.columns:
                continue
            
            series = window_data[feat].values
            
            if len(series) < 2:
                continue
            
            # è·³è¿‡å…¨ä¸ºé›¶æˆ–æ— æ•ˆçš„åºåˆ—
            if np.all(series == 0) or not np.any(np.isfinite(series)):
                continue
            
            prefix = f'{feat}_w{window}'
            
            # ğŸ”¥ æ ¹æ®ç‰¹å¾ç±»å‹æ™ºèƒ½é€‰æ‹©ç»Ÿè®¡é‡
            selected_stats = self._get_statistics_for_feature(feat)
            
            # è®¡ç®—é€‰ä¸­çš„ç»Ÿè®¡é‡
            # 1. åŸºç¡€ç»Ÿè®¡é‡
            if 'mean' in selected_stats:
                features[f'{prefix}_mean'] = float(np.mean(series))
            if 'std' in selected_stats:
                features[f'{prefix}_std'] = float(np.std(series))
            if 'min' in selected_stats:
                features[f'{prefix}_min'] = float(np.min(series))
            if 'max' in selected_stats:
                features[f'{prefix}_max'] = float(np.max(series))
            
            # 2. è¶‹åŠ¿ç‰¹å¾
            if 'trend' in selected_stats:
                if series[0] != 0 and np.isfinite(series[0]):
                    features[f'{prefix}_trend'] = float((series[-1] - series[0]) / (np.abs(series[0]) + 1e-12))
                else:
                    features[f'{prefix}_trend'] = 0.0
            
            if 'momentum' in selected_stats:
                # åŠ¨é‡ï¼ˆå1/4 vs å‰1/4ï¼‰
                q = window // 4
                if q >= 1:
                    features[f'{prefix}_momentum'] = float(np.mean(series[-q:]) - np.mean(series[:q]))
            
            if 'slope' in selected_stats:
                # çº¿æ€§å›å½’æ–œç‡
                if len(series) >= 3:
                    try:
                        x = np.arange(len(series))
                        slope, _, _, _, _ = linregress(x, series)
                        features[f'{prefix}_slope'] = float(slope)
                    except:
                        pass  # è·³è¿‡è®¡ç®—å¤±è´¥çš„æƒ…å†µ
            
            # 3. ç›¸å¯¹ä½ç½®ç‰¹å¾
            if 'zscore' in selected_stats or 'quantile' in selected_stats:
                current_val = series[-1]
                mean_val = np.mean(series)
                std_val = np.std(series)
                
                if 'zscore' in selected_stats:
                    if std_val > 0 and np.isfinite(std_val):
                        features[f'{prefix}_zscore'] = float((current_val - mean_val) / std_val)
                    else:
                        features[f'{prefix}_zscore'] = 0.0
                
                if 'quantile' in selected_stats and len(series) >= 5:
                    # åˆ†ä½æ•°ä½ç½®
                    rank = np.sum(series < current_val)
                    features[f'{prefix}_quantile'] = float(rank / len(series))
            
            # 4. æ³¢åŠ¨ç‰¹å¾
            if 'range_norm' in selected_stats:
                range_val = np.max(series) - np.min(series)
                mean_val = np.mean(series)
                if mean_val != 0:
                    features[f'{prefix}_range_norm'] = float(range_val / (np.abs(mean_val) + 1e-12))
                else:
                    features[f'{prefix}_range_norm'] = 0.0
            
            # 5. åŠ é€Ÿåº¦ï¼ˆäºŒé˜¶è¶‹åŠ¿ï¼‰
            if 'acceleration' in selected_stats and len(series) >= 3:
                recent_trend = series[-1] - series[-2] if len(series) >= 2 else 0
                early_trend = series[1] - series[0] if len(series) >= 2 else 0
                features[f'{prefix}_acceleration'] = float(recent_trend - early_trend)
            
            # 6. è‡ªç›¸å…³ï¼ˆlag=1ï¼‰
            if 'autocorr' in selected_stats and len(series) >= 3:
                try:
                    corr = np.corrcoef(series[:-1], series[1:])[0, 1]
                    if np.isfinite(corr):
                        features[f'{prefix}_autocorr'] = float(corr)
                except:
                    pass  # è·³è¿‡è®¡ç®—å¤±è´¥çš„æƒ…å†µ
        
        # 7. äº¤å‰ç‰¹å¾ç›¸å…³æ€§ï¼ˆè‡ªåŠ¨æŸ¥æ‰¾åŒ¹é…çš„ç‰¹å¾ï¼‰
        # RV vs VPIN
        rv_cols = [col for col in window_data.columns if 'rv' in col.lower() and not 'corr' in col.lower()]
        vpin_cols = [col for col in window_data.columns if 'vpin' in col.lower()]
        
        if rv_cols and vpin_cols:
            try:
                rv_col = rv_cols[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªåŒ¹é…çš„
                vpin_col = vpin_cols[0]
                rv_series = window_data[rv_col].values
                vpin_series = window_data[vpin_col].values
                if len(rv_series) >= 3 and np.std(rv_series) > 0 and np.std(vpin_series) > 0:
                    corr = np.corrcoef(rv_series, vpin_series)[0, 1]
                    if np.isfinite(corr):
                        features[f'rv_vpin_corr_w{window}'] = float(corr)
            except:
                pass
        
        # Large vs Small
        large_cols = [col for col in window_data.columns if 'large' in col.lower() and 'signed' in col.lower()]
        small_cols = [col for col in window_data.columns if 'small' in col.lower() and 'signed' in col.lower()]
        
        if large_cols and small_cols:
            try:
                large_col = large_cols[0]
                small_col = small_cols[0]
                large_series = window_data[large_col].values
                small_series = window_data[small_col].values
                if len(large_series) >= 3 and np.std(large_series) > 0 and np.std(small_series) > 0:
                    corr = np.corrcoef(large_series, small_series)[0, 1]
                    if np.isfinite(corr):
                        features[f'large_small_corr_w{window}'] = float(corr)
            except:
                pass
        
        return features
    
    def _sum_range(self, cumsum_array: np.ndarray, start: int, end: int) -> float:
        """åˆ©ç”¨å‰ç¼€å’Œè®¡ç®—åŒºé—´å’Œï¼ˆO(1)ï¼‰"""
        if start >= len(cumsum_array) or end > len(cumsum_array):
            return 0.0
        if start == 0:
            return float(cumsum_array[end - 1])
        return float(cumsum_array[end - 1] - cumsum_array[start - 1])
    
    def _calculate_vpin(self, dv: np.ndarray, sign: np.ndarray, bins: int = 10) -> float:
        """è®¡ç®— VPIN (Volume-synchronized Probability of Informed Trading)"""
        total = dv.sum()
        if total <= 0 or len(dv) < bins:
            return 0.0
        
        target = total / bins
        acc = 0.0
        buy = 0.0
        sell = 0.0
        vals = []
        
        for i in range(len(dv)):
            q = dv[i]
            acc += q
            if sign[i] > 0:
                buy += q
            elif sign[i] < 0:
                sell += q
            
            if acc >= target:
                denom = buy + sell
                v = abs(buy - sell) / denom if denom > 0 else 0.0
                vals.append(v)
                acc = 0.0
                buy = 0.0
                sell = 0.0
        
        if not vals:
            return 0.0
        
        return float(np.mean(vals))
    
    def get_feature_names(self, window: int, bar_features_df: Optional[pd.DataFrame] = None) -> List[str]:
        """è·å–ç”Ÿæˆçš„ç‰¹å¾åç§°åˆ—è¡¨
        
        å‚æ•°:
            window: æ»šåŠ¨çª—å£å¤§å°
            bar_features_df: bar çº§ç‰¹å¾ DataFrameï¼ˆç”¨äºè‡ªåŠ¨è¯†åˆ«ç‰¹å¾ï¼‰
        
        è¿”å›:
            ç‰¹å¾åç§°åˆ—è¡¨
        """
        # å¦‚æœæä¾›äº† bar_features_dfï¼Œè‡ªåŠ¨è¯†åˆ«ç‰¹å¾
        if bar_features_df is not None:
            base_features = [col for col in bar_features_df.columns 
                           if col.startswith('bar_') and 
                           pd.api.types.is_numeric_dtype(bar_features_df[col])]
        else:
            # ä½¿ç”¨å·²çŸ¥çš„ç‰¹å¾æå–å™¨è·å–ç‰¹å¾åç§°
            if self.feature_extractor is not None:
                # è·å–ç‰¹å¾æå–å™¨çš„æ‰€æœ‰ç‰¹å¾åç§°
                extractor_features = self.feature_extractor.get_feature_names()
                base_features = [f'bar_{feat}' for feat in extractor_features]
            else:
                # å›é€€åˆ°é»˜è®¤åˆ—è¡¨
                base_features = [
                    'bar_rv', 'bar_bpv', 'bar_jump',
                    'bar_vpin', 'bar_small_signed_dollar', 'bar_large_signed_dollar',
                    'bar_hl_ratio', 'bar_signed_volume', 'bar_volume'
                ]
        
        suffixes = ['mean', 'std', 'min', 'max', 'trend', 'momentum', 'slope', 
                   'zscore', 'quantile', 'range_norm', 'acceleration', 'autocorr']
        
        names = []
        for feat in base_features:
            for suffix in suffixes:
                names.append(f'{feat}_w{window}_{suffix}')
        
        # äº¤å‰ç‰¹å¾ï¼ˆå¦‚æœå­˜åœ¨ç›¸å…³ç‰¹å¾ï¼‰
        if any('rv' in f for f in base_features) and any('vpin' in f for f in base_features):
            names.append(f'rv_vpin_corr_w{window}')
        if any('large' in f for f in base_features) and any('small' in f for f in base_features):
            names.append(f'large_small_corr_w{window}')
        
        return names

