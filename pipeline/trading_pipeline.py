"""
äº¤æ˜“åˆ†æç®¡é“ä¸»æ§åˆ¶å™¨
"""
import os
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime, timedelta

from core.base import ConfigManager
from data.trades_processor import TradesProcessor
from data.dollar_bars import DollarBarBuilder
from data.time_bars import TimeBarBuilder
# from features import MicrostructureFeatureExtractor
from features.microstructure_extractor import MicrostructureFeatureExtractor
from ml.models import ModelFactory
from ml.validators import PurgedBarValidator
# from utils.visualization import TradingVisualizer


class TradingPipeline:
    """äº¤æ˜“åˆ†æç®¡é“ä¸»æ§åˆ¶å™¨"""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config_manager = ConfigManager()
        if config:
            for module, module_config in config.items():
                self.config_manager.set_config(module, module_config)
        
        # è®¾ç½®é»˜è®¤æ ‡ç­¾é…ç½®
        default_label_config = {
            'horizon_bars': [1, 3, 5, 10]  # é»˜è®¤é¢„æµ‹æŒæœ‰æœŸï¼ˆä»¥barä¸ºå•ä½ï¼‰
        }
        if 'labels' not in self.config_manager._configs:
            self.config_manager.set_config('labels', default_label_config)
        
        # è®¾ç½®é»˜è®¤æ•°æ®é…ç½®
        default_data_config = {
            'load_mode': 'auto',  # 'daily', 'monthly', 'auto'
            'prefer_feather': True
        }
        if 'data' not in self.config_manager._configs:
            self.config_manager.set_config('data', default_data_config)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.trades_processor = TradesProcessor()
        # è®¾ç½®é»˜è®¤ç‰¹å¾é…ç½®ï¼ˆå¼€å¯ bucketed_flowï¼‰
        default_features_config = {
            'bucketed_flow': {
                'enabled': True,
                'low_q': 0.2,
                'high_q': 0.8,
                'lag': 1,
                'vpin_bins': 10,
                'min_trades_alpha': 50
            },
            # å…¶ä½™ä¿ç•™åŸæœ‰é»˜è®¤
        }
        if 'features' not in self.config_manager._configs:
            self.config_manager.set_config('features', default_features_config)
        else:
            # å°†é»˜è®¤é¡¹ä¸å¤–éƒ¨ä¼ å…¥åˆå¹¶ï¼ˆä»…è¡¥å……ç¼ºå¤±é”®ï¼‰
            feat_cfg = self.config_manager.get_config('features') or {}
            for k, v in default_features_config.items():
                if k not in feat_cfg:
                    feat_cfg[k] = v
            self.config_manager.set_config('features', feat_cfg)

        self.feature_extractor = MicrostructureFeatureExtractor(
            self.config_manager.get_config('features')
        )
        # self.visualizer = TradingVisualizer()
        
        # è¿è¡Œæ—¶æ•°æ®
        self.trades_context = None
        self.bars = None
        self.features = None
        self.labels = None
        self.model = None
        self.evaluation_results = None
    
    def load_data(self, trades_data: Optional[pd.DataFrame] = None,
                  date_range: Optional[Tuple[str, str]] = None,
                  daily_data_template: Optional[str] = None,
                  monthly_data_template: Optional[str] = None) -> pd.DataFrame:
        """åŠ è½½äº¤æ˜“æ•°æ®ï¼ˆæ”¯æŒæŒ‰æ—¥/æŒ‰æœˆ/è‡ªåŠ¨æ¨¡å¼ï¼‰
        
        å‚æ•°:
            trades_data: ç›´æ¥æä¾›çš„DataFrame
            date_range: æ—¥æœŸèŒƒå›´ (start_date, end_date)
            daily_data_template: æ—¥æ•°æ®è·¯å¾„æ¨¡æ¿ï¼Œæ”¯æŒ {date} å’Œ {ext}
            monthly_data_template: æœˆæ•°æ®è·¯å¾„æ¨¡æ¿ï¼Œæ”¯æŒ {month} å’Œ {ext}
        
        åŠ è½½é€»è¾‘:
            1. å¦‚æœæä¾› trades_dataï¼Œç›´æ¥è¿”å›
            2. æ ¹æ®é…ç½®çš„ load_mode å†³å®šåŠ è½½æ–¹å¼ï¼š
               - 'monthly': ä¼˜å…ˆä½¿ç”¨æœˆåº¦æ–‡ä»¶
               - 'daily': ä½¿ç”¨æ—¥æ•°æ®æ–‡ä»¶
               - 'auto': è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ–¹æ¡ˆï¼ˆé»˜è®¤ï¼‰
        """
        if trades_data is not None:
            return trades_data
        
        if not (date_range and (daily_data_template or monthly_data_template)):
            raise ValueError("å¿…é¡»æä¾› date_range å’Œè‡³å°‘ä¸€ä¸ªæ•°æ®æ¨¡æ¿")
        
        # è·å–æ•°æ®åŠ è½½é…ç½®
        data_config = self.config_manager.get_config('data')
        load_mode = data_config.get('load_mode', 'auto')
        prefer_feather = data_config.get('prefer_feather', True)
        
        start_date, end_date = date_range
        
        # æ ¹æ® load_mode å†³å®šåŠ è½½ç­–ç•¥
        if load_mode == 'monthly' and monthly_data_template:
            return self._load_monthly_data(start_date, end_date, monthly_data_template, prefer_feather)
        elif load_mode == 'daily' and daily_data_template:
            return self._load_daily_data(start_date, end_date, daily_data_template, prefer_feather)
        elif load_mode == 'auto':
            # è‡ªåŠ¨é€‰æ‹©ï¼šä¼˜å…ˆå°è¯•æœˆåº¦æ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨æ—¥æ•°æ®
            return self._load_auto_data(start_date, end_date, daily_data_template, monthly_data_template, prefer_feather)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ load_mode: {load_mode} æˆ–ç¼ºå°‘å¯¹åº”çš„æ•°æ®æ¨¡æ¿")
    
    def _load_monthly_data(self, start_date: str, end_date: str, 
                          monthly_template: str, prefer_feather: bool = True) -> pd.DataFrame:
        """æŒ‰æœˆåŠ è½½æ•°æ®"""
        from datetime import datetime
        from dateutil.relativedelta import relativedelta
        
        start = datetime.strptime(start_date, '%Y-%m-%d')
        end = datetime.strptime(end_date, '%Y-%m-%d')
        
        # ç”Ÿæˆæœˆä»½åˆ—è¡¨
        months = []
        current = start.replace(day=1)
        while current <= end:
            months.append(current.strftime('%Y-%m'))
            current += relativedelta(months=1)
        
        print(f"ğŸ“‚ æŒ‰æœˆåŠ è½½æ•°æ®: {start_date} åˆ° {end_date} ({len(months)} ä¸ªæœˆ)")
        raw_df = []
        
        exts = ['feather', 'zip'] if prefer_feather else ['zip', 'feather']
        
        for month in months:
            loaded = False
            for ext in exts:
                file_path = monthly_template.format(month=month, ext=ext)
                if os.path.exists(file_path):
                    if ext == 'feather':
                        df = pd.read_feather(file_path)
                    else:
                        df = pd.read_csv(file_path)
                    raw_df.append(df)
                    print(f"   âœ“ åŠ è½½ {month} ({ext})")
                    loaded = True
                    break
            
            if not loaded:
                print(f"   âš ï¸  è­¦å‘Š: æœˆåº¦æ–‡ä»¶ä¸å­˜åœ¨ {month}")
        
        if not raw_df:
            raise ValueError("æœªæ‰¾åˆ°ä»»ä½•æœˆåº¦æ•°æ®æ–‡ä»¶")
        
        print(f"âœ… åŠ è½½äº† {len(raw_df)} ä¸ªæœˆåº¦æ–‡ä»¶ï¼Œå¼€å§‹åˆå¹¶...")
        trades_df = pd.concat(raw_df, ignore_index=True, copy=False)
        
        # è¿‡æ»¤åˆ°æŒ‡å®šæ—¥æœŸèŒƒå›´
        # trades_df = self._filter_date_range(trades_df, start_date, end_date)
        # print(f"âœ… åˆå¹¶å®Œæˆï¼Œè¿‡æ»¤åå…± {len(trades_df):,} æ¡è®°å½•")
        
        return trades_df
    
    def _load_daily_data(self, start_date: str, end_date: str,
                        daily_template: str, prefer_feather: bool = True) -> pd.DataFrame:
        """æŒ‰æ—¥åŠ è½½æ•°æ®"""
        date_list = self._generate_date_range(start_date, end_date)
        
        print(f"ğŸ“‚ æŒ‰æ—¥åŠ è½½æ•°æ®: {start_date} åˆ° {end_date} ({len(date_list)} å¤©)")
        raw_df = []
        
        exts = ['feather', 'zip'] if prefer_feather else ['zip', 'feather']
        
        for i, date in enumerate(date_list, 1):
            loaded = False
            for ext in exts:
                file_path = daily_template.format(date=date, ext=ext)
                if os.path.exists(file_path):
                    if ext == 'feather':
                        df = pd.read_feather(file_path)
                    else:
                        df = pd.read_csv(file_path)
                    raw_df.append(df)
                    loaded = True
                    break
            
            if not loaded:
                print(f"   âš ï¸  è­¦å‘Š: æ—¥æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ {date}")
            elif i % 10 == 0:
                print(f"   å·²åŠ è½½ {i}/{len(date_list)} ä¸ªæ–‡ä»¶...")
        
        if not raw_df:
            raise ValueError("æœªæ‰¾åˆ°ä»»ä½•æ—¥æ•°æ®æ–‡ä»¶")
        
        print(f"âœ… åŠ è½½äº† {len(raw_df)} ä¸ªæ—¥æ–‡ä»¶ï¼Œå¼€å§‹åˆå¹¶...")
        trades_df = pd.concat(raw_df, ignore_index=True, copy=False)
        print(f"âœ… åˆå¹¶å®Œæˆï¼Œå…± {len(trades_df):,} æ¡è®°å½•")
        
        return trades_df
    
    def _load_auto_data(self, start_date: str, end_date: str,
                       daily_template: Optional[str], monthly_template: Optional[str],
                       prefer_feather: bool = True) -> pd.DataFrame:
        """è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜åŠ è½½æ–¹æ¡ˆ"""
        from datetime import datetime
        
        start = datetime.strptime(start_date, '%Y-%m-%d')
        end = datetime.strptime(end_date, '%Y-%m-%d')
        days_span = (end - start).days + 1
        
        # å¦‚æœè·¨åº¦è¶…è¿‡ 10 å¤©ä¸”æœ‰æœˆåº¦æ–‡ä»¶å¯ç”¨ï¼Œä¼˜å…ˆå°è¯•æœˆåº¦
        if days_span > 10 and monthly_template:
            print(f"ğŸ” è‡ªåŠ¨æ¨¡å¼ï¼šæ•°æ®è·¨åº¦ {days_span} å¤©ï¼Œå°è¯•ä½¿ç”¨æœˆåº¦æ•°æ®...")
            try:
                return self._load_monthly_data(start_date, end_date, monthly_template, prefer_feather)
            except (ValueError, FileNotFoundError) as e:
                print(f"   æœˆåº¦æ•°æ®åŠ è½½å¤±è´¥ï¼Œå›é€€åˆ°æ—¥æ•°æ®: {e}")
        
        # å›é€€åˆ°æ—¥æ•°æ®
        if daily_template:
            print(f"ğŸ” è‡ªåŠ¨æ¨¡å¼ï¼šä½¿ç”¨æ—¥æ•°æ®åŠ è½½...")
            return self._load_daily_data(start_date, end_date, daily_template, prefer_feather)
        else:
            raise ValueError("æ— å¯ç”¨çš„æ•°æ®æ¨¡æ¿")
    
    def _filter_date_range(self, df: pd.DataFrame, start_date: str, end_date: str) -> pd.DataFrame:
        """è¿‡æ»¤æ•°æ®åˆ°æŒ‡å®šæ—¥æœŸèŒƒå›´"""
        # ç¡®ä¿ time åˆ—æ˜¯ datetime ç±»å‹
        if 'time' in df.columns:
            if not pd.api.types.is_datetime64_any_dtype(df['time']):
                df['time'] = pd.to_datetime(df['time'], unit='ms', errors='coerce')
            
            start = pd.to_datetime(start_date)
            end = pd.to_datetime(end_date) + pd.Timedelta(days=1) - pd.Timedelta(microseconds=1)
            
            mask = (df['time'] >= start) & (df['time'] <= end)
            return df[mask].reset_index(drop=True)
        
        return df
    
    def build_bars(self,
                   trades_df: pd.DataFrame,
                   dollar_threshold: float,
                   bar_cache_template: Optional[str] = None,
                   bar_zip_path: Optional[str] = None,  # å‘åå…¼å®¹
                   bar_type: str = 'dollar',
                   time_freq: Optional[str] = None) -> pd.DataFrame:
        """æ„å»º Barsï¼ˆæ”¯æŒ Dollar å’Œ Timeï¼‰

        å‚æ•°:
            trades_df: äº¤æ˜“æ•°æ®
            dollar_threshold: dollar bar é˜ˆå€¼
            bar_cache_template: ç¼“å­˜è·¯å¾„æ¨¡æ¿ï¼Œæ”¯æŒ {ext}ï¼Œå¦‚ 'path/bars.{ext}'
            bar_zip_path: (å·²åºŸå¼ƒ) ç›´æ¥æŒ‡å®šzipè·¯å¾„ï¼Œä»…ä¸ºå‘åå…¼å®¹ä¿ç•™
            bar_type: 'dollar' æˆ– 'time'
            time_freq: å½“ bar_type='time' æ—¶çš„é¢‘ç‡å­—ç¬¦ä¸²ï¼ˆå¦‚ '1H', '15min'ï¼‰
        
        åŠ è½½ä¼˜å…ˆçº§:
            1. feather ç¼“å­˜ï¼ˆæœ€å¿«ï¼‰
            2. zip ç¼“å­˜
            3. æ„å»ºæ–°çš„barså¹¶ç¼“å­˜
        """
        # å‘åå…¼å®¹ï¼šå¦‚æœåªæä¾›äº† bar_zip_pathï¼Œè½¬æ¢ä¸º template
        if bar_zip_path and not bar_cache_template:
            bar_cache_template = bar_zip_path.replace('.zip', '.{ext}')
        
        # ä¼˜å…ˆä» feather ç¼“å­˜åŠ è½½
        if bar_cache_template:
            feather_path = bar_cache_template.format(ext='feather')
            if os.path.exists(feather_path):
                print(f"âœ“ ä» Feather ç¼“å­˜åŠ è½½ bars: {feather_path}")
                bars = pd.read_feather(feather_path)
                self.bars = bars
                return bars
            
            # å…¶æ¬¡ä» zip ç¼“å­˜åŠ è½½
            zip_path = bar_cache_template.format(ext='zip')
            if os.path.exists(zip_path):
                print(f"âœ“ ä» ZIP ç¼“å­˜åŠ è½½ bars: {zip_path}")
                bars = pd.read_csv(zip_path)
                
                # è½¬å­˜ä¸º feather æ ¼å¼
                print(f"â†’ è½¬å­˜ä¸º Feather æ ¼å¼: {feather_path}")
                os.makedirs(os.path.dirname(feather_path), exist_ok=True)
                bars.to_feather(feather_path)
                
                self.bars = bars
                return bars
        
        # æ„å»ºæ–°çš„ bars
        if bar_type == 'time':
            freq = time_freq or '1H'
            print(f"æ„å»º Time Barsï¼ˆfreq={freq}ï¼‰...")
            bar_builder = TimeBarBuilder(freq=freq)
        else:
            print(f"æ„å»º Dollar Barsï¼ˆthreshold={dollar_threshold:,.0f}ï¼‰...")
            bar_builder = DollarBarBuilder(dollar_threshold)

        bars = bar_builder.process(trades_df)
        print(f"âœ“ æ„å»ºäº† {len(bars)} ä¸ª bars")
            
        # ç¼“å­˜å·²å¤„ç†çš„ trades ä¸Šä¸‹æ–‡ï¼ˆé¿å…åœ¨ extract_features ä¸­é‡å¤å¤„ç†ï¼‰
        self.trades_context = bar_builder.trades_processor.context
        

        # ä¿å­˜ç¼“å­˜ï¼ˆåŒæ—¶ä¿å­˜ feather å’Œ zipï¼‰
        if bar_cache_template:
            feather_path = bar_cache_template.format(ext='feather')
            zip_path = bar_cache_template.format(ext='zip')
            
            print(f"â†’ ä¿å­˜ Feather ç¼“å­˜: {feather_path}")
            os.makedirs(os.path.dirname(feather_path), exist_ok=True)
            bars.to_feather(feather_path)
            
            print(f"â†’ ä¿å­˜ ZIP ç¼“å­˜: {zip_path}")
            os.makedirs(os.path.dirname(zip_path), exist_ok=True)
            bars.to_csv(
                zip_path, 
                index=False,
                compression={'method': 'zip', 'archive_name': 'bars.csv'}
            )
        
        self.bars = bars
        return bars
    
    def extract_features(self, trades_df: pd.DataFrame, bars: pd.DataFrame,
                        feature_window_bars: int = 10) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """æå–ç‰¹å¾å’Œæ ‡ç­¾"""
        # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰ç¼“å­˜çš„ trades_contextï¼ˆæ¥è‡ª build_barsï¼‰
        if not hasattr(self, 'trades_context') or self.trades_context is None:
            print("æ„å»ºäº¤æ˜“ä¸Šä¸‹æ–‡...")
            self.trades_context = self.trades_processor.build_context(trades_df)
        else:
            print("âœ“ ä½¿ç”¨å·²ç¼“å­˜çš„äº¤æ˜“ä¸Šä¸‹æ–‡ï¼ˆé¿å…é‡å¤å¤„ç†ï¼‰")
        
        print("æå–ç‰¹å¾...")
        features_list = []
        labels_list = []
        
        bars = bars.reset_index(drop=True)
        bars['bar_id'] = bars.index
        bars['start_time'] = pd.to_datetime(bars['start_time'])
        bars['end_time'] = pd.to_datetime(bars['end_time'])
        
        close_prices = bars.set_index('bar_id')['close']
        end_times = bars.set_index('bar_id')['end_time']
        
        # è®¡ç®—æ ‡ç­¾ï¼ˆå¤šä¸ªæŒæœ‰æœŸï¼‰
        label_config = self.config_manager.get_config('labels')
        horizon_bars = label_config.get('horizon_bars', [1, 3, 5, 10])
        labels_df = pd.DataFrame(index=close_prices.index)
        
        for horizon in horizon_bars:
            log_return = np.log(close_prices.shift(-horizon) / close_prices)
            labels_df[f'log_return_{horizon}'] = log_return
            labels_df[f't0_time_{horizon}'] = end_times
            labels_df[f'tH_time_{horizon}'] = end_times.shift(-horizon)
        
        # æå–ç‰¹å¾
        idx = 1
        for bar_id in close_prices.index:
            bar_window_start_idx = bar_id - feature_window_bars
            if bar_window_start_idx < 0:
                continue
            
            bar_window_end_idx = bar_id - 1
            
            feature_start_ts = bars.loc[bar_window_start_idx, 'start_time']
            feature_end_ts = bars.loc[bar_window_end_idx, 'end_time']
            
            # æå–å¾®è§‚ç»“æ„ç‰¹å¾
            features = self.feature_extractor.extract_from_context(
                ctx=self.trades_context,
                start_ts=feature_start_ts,
                end_ts=feature_end_ts,
                bars=bars,
                bar_window_start_idx=bar_window_start_idx,
                bar_window_end_idx=bar_window_end_idx
            )
            
            if idx % 100 == 0:
                print(f"å¤„ç†è¿›åº¦: {idx}/{len(close_prices.index)}")
            idx += 1
            
            features['bar_id'] = bar_id
            features['feature_start'] = feature_start_ts
            features['feature_end'] = feature_end_ts
            features['prediction_time'] = bars.loc[bar_id, 'end_time']
            
            features_list.append(features)
        
        # æ„å»ºç‰¹å¾DataFrame
        X = pd.DataFrame(features_list).set_index('bar_id')
        y = labels_df.loc[X.index]
        
        # è¿‡æ»¤æ— æ•ˆæ•°æ®ï¼ˆåˆ†æ­¥å¤„ç†ï¼Œç¡®ä¿ X å’Œ y ä¸¥æ ¼å¯¹é½ï¼‰
        # æ­¥éª¤ 1: è¿‡æ»¤ y ä¸­æ‰€æœ‰ log_return åˆ—çš„æ— æ•ˆå€¼
        log_return_cols = [col for col in y.columns if col.startswith('log_return_')]
        y_mask = pd.Series(True, index=y.index)
        for col in log_return_cols:
            y_mask &= y[col].notna() & np.isfinite(y[col].values)
        
        X = X.loc[y_mask]
        y = y.loc[y_mask]
        
        # æ­¥éª¤ 2: æ›¿æ¢ X ä¸­çš„ inf ä¸º nan
        X = X.replace([np.inf, -np.inf], np.nan)
        
        # æ­¥éª¤ 3: åˆ é™¤ X ä¸­åŒ…å« NaN çš„è¡Œï¼Œå¹¶åŒæ­¥åˆ é™¤ y ä¸­å¯¹åº”çš„è¡Œ
        x_valid_mask = ~X.isna().any(axis=1)
        X = X.loc[x_valid_mask]
        y = y.loc[x_valid_mask]
        
        self.features = X
        self.labels = y
        
        return X, y
    
    def train_and_evaluate(self, X: pd.DataFrame, y: pd.DataFrame,
                          model_type: str = 'ridge',
                          target_horizon: int = 5,
                          n_splits: int = 5,
                          embargo_bars: int = 3) -> Dict:
        """è®­ç»ƒæ¨¡å‹å¹¶è¯„ä¼°"""
        print(f"å¼€å§‹è®­ç»ƒ{model_type}æ¨¡å‹...")
        
        # é€‰æ‹©ç›®æ ‡æ ‡ç­¾
        target_col = f'log_return_{target_horizon}'
        if target_col not in y.columns:
            raise ValueError(f"æ ‡ç­¾åˆ—{target_col}ä¸å­˜åœ¨")
        
        y_target = y[target_col]
        
        # è¿‡æ»¤ç‰¹å¾åˆ—ï¼ˆæ’é™¤æ—¶é—´ç›¸å…³åˆ—ï¼‰
        feature_cols = [col for col in X.columns 
                       if not any(time_word in col.lower() 
                                for time_word in ['time', 'start', 'end', 'settle'])]
        X_features = X[feature_cols]
        
        # åˆ›å»ºæ¨¡å‹
        model_config = self.config_manager.get_config('model')
        self.model = ModelFactory.create_model(model_type, **model_config)
        
        # äº¤å‰éªŒè¯
        validator = PurgedBarValidator(n_splits=n_splits, embargo_bars=embargo_bars)
        results = validator.evaluate(self.model, X_features, y_target)
        
        self.evaluation_results = results
        
        print("æ¨¡å‹è¯„ä¼°å®Œæˆ!")
        print(f"å¹³å‡Pearson IC: {results['summary']['pearson_ic_mean']:.4f}")
        print(f"å¹³å‡Spearman IC: {results['summary']['spearman_ic_mean']:.4f}")
        print(f"å¹³å‡RMSE: {results['summary']['rmse_mean']:.4f}")
        print(f"å¹³å‡æ–¹å‘å‡†ç¡®ç‡: {results['summary']['dir_acc_mean']:.4f}")
        
        return results
    
    def visualize_results(self, save_dir: Optional[str] = None):
        """å¯è§†åŒ–ç»“æœ"""
        if self.evaluation_results is None:
            print("å°šæœªè¿›è¡Œæ¨¡å‹è¯„ä¼°")
            return
        
        predictions = self.evaluation_results['predictions']
        target_col = f'log_return_5'  # å‡è®¾ä½¿ç”¨5æœŸä½œä¸ºç›®æ ‡
        y_true = self.labels[target_col].loc[predictions.index]
        
        # self.visualizer.plot_predictions_vs_truth(
        #     predictions, y_true, 
        #     title="é¢„æµ‹å€¼ vs çœŸå®å€¼",
        #     save_path=os.path.join(save_dir, "predictions_vs_truth.png") if save_dir else None
        # )
        
        # ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§
        if hasattr(self.model, 'get_feature_importance'):
            importance = self.model.get_feature_importance()
            # self.visualizer.plot_feature_importance(
            #     importance,
            #     title="ç‰¹å¾é‡è¦æ€§",
            #     save_path=os.path.join(save_dir, "feature_importance.png") if save_dir else None
            # )
    
    def run_full_pipeline(self, **kwargs) -> Dict:
        """è¿è¡Œå®Œæ•´çš„åˆ†æç®¡é“"""
        # å…è®¸é€šè¿‡ kwargs.features_config è¦†ç›–ç‰¹å¾é…ç½®
        features_override = kwargs.get('features_config')
        if features_override is not None:
            feat_cfg = self.config_manager.get_config('features') or {}
            # æµ…åˆå¹¶ï¼šä»¥å¤–éƒ¨ä¸ºå‡†
            for k, v in features_override.items():
                feat_cfg[k] = v
            self.config_manager.set_config('features', feat_cfg)
            # é‡å»ºç‰¹å¾æå–å™¨
            self.feature_extractor = MicrostructureFeatureExtractor(feat_cfg)
        # åŠ è½½æ•°æ®
        trades_df = self.load_data(**kwargs.get('data_config', {}))
        print(f"åŠ è½½äº†{len(trades_df)}æ¡äº¤æ˜“è®°å½•")
        
        # æ„å»ºbars
        dollar_threshold = kwargs.get('dollar_threshold', 60000000)
        bar_type = kwargs.get('bar_type', 'dollar')
        time_freq = kwargs.get('time_freq')
        bars = self.build_bars(
            trades_df,
            dollar_threshold,
            bar_cache_template=kwargs.get('bar_cache_template'),
            bar_zip_path=kwargs.get('bar_zip_path'),  # å‘åå…¼å®¹
            bar_type=bar_type,
            time_freq=time_freq,
        )
        
        # æå–ç‰¹å¾
        feature_window_bars = kwargs.get('feature_window_bars', 10)
        X, y = self.extract_features(trades_df, bars, feature_window_bars)
        print(f"æå–äº†{len(X)}ä¸ªæ ·æœ¬ï¼Œ{len(X.columns)}ä¸ªç‰¹å¾")
        
        # è®­ç»ƒè¯„ä¼°
        results = self.train_and_evaluate(
            X, y,
            model_type=kwargs.get('model_type', 'ridge'),
            target_horizon=kwargs.get('target_horizon', 5),
            n_splits=kwargs.get('n_splits', 5),
            embargo_bars=kwargs.get('embargo_bars', 3)
        )
        
        # å¯è§†åŒ–
        if kwargs.get('save_plots'):
            self.visualize_results(kwargs.get('plot_save_dir'))
        
        return {
            'evaluation': results,
            'features': X,
            'labels': y,
            'bars': bars,
            'model': self.model
        }
    
    def _generate_date_range(self, start_date: str, end_date: str) -> List[str]:
        """ç”Ÿæˆæ—¥æœŸèŒƒå›´"""
        start = datetime.strptime(start_date, '%Y-%m-%d')
        end = datetime.strptime(end_date, '%Y-%m-%d')
        
        date_list = []
        current = start
        while current <= end:
            date_list.append(current.strftime('%Y-%m-%d'))
            current += timedelta(days=1)
        return date_list
